{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3af6ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing conservative water balance method to calculate the Bedrock Water Deficit \\nAuthor: Xionghui Xu\\nDate: July 10, 2025\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using conservative water balance method to calculate the Bedrock Water Deficit \n",
    "Author: Xionghui Xu\n",
    "Date: July 10, 2025\n",
    "\"\"\"\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import netCDF4 as nc\n",
    "import subprocess\n",
    "import shutil\n",
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a4651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here we set the configuration for the water balance method\n",
    "resolution = \"500\"\n",
    "region = [-180,180,-60,90]\n",
    "data_path = f'data/run/'\n",
    "shp_path = 'data/Shp/'\n",
    "fig_path = 'fig/'\n",
    "path = 'data/'\n",
    "mask_path = 'data/run/masking_criteria/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e46e22",
   "metadata": {},
   "source": [
    "# Calculate the Bedrock Water Storage Deficit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92377f32",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "## !!! Due to limited data storage, the data required for the data preprocessing process is not provided, so the following data preprocessing code cannot be used and is for reference only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d721e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command:str):\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error executing command: {command}\")\n",
    "        print(result.stderr)\n",
    "        raise RuntimeError(\"CDO command failed\")\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the masking criteria include: \n",
    "1. mask area without adequate water (sum ET>P from 2003 to 2020)\n",
    "2. mask area without woody vegetation (IGBP=1~9)\n",
    "3. mask area without shallow bedrock (DTB<150cm)\n",
    "the masking criteria need to calculate after the Dbedrock calculation.\n",
    "\"\"\"\n",
    "# def mask():\n",
    "#     def mask_adequate_water() -> None:\n",
    "#         diff_file = os.path.join(path, 'diff', 'diff.nc4')\n",
    "#         dir_path = os.path.join(path, 'masking_criteria')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         output_sum = os.path.join(dir_path, 'diff_sum.nc4')\n",
    "#         output_interp = os.path.join(dir_path, 'diff_sum_interp.nc4')\n",
    "#         mask_file = os.path.join(dir_path, 'mask_adequate_water.nc4')\n",
    "#         run_command(f\"cdo -f nc4 -P 48 timsum {diff_file} {output_sum}\")\n",
    "#         run_command(f\"gdalwarp -multi -wo NUM_THREADS=48 -ot Float32 -of netCDF -co FORMAT=NC4 -r bilinear -ts 86400 43200 -overwrite {output_sum} {output_interp}\")\n",
    "#         run_command(f\"cdo -f nc4 -z zip -setrtoc2,0,inf,nan,1 {output_interp} {mask_file}\")\n",
    "#         print(\"mask_adequate_water completed\")\n",
    "\n",
    "#     def mask_woody_veg() -> None:\n",
    "#         dir_path = os.path.join(path, 'masking_criteria')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         igbp_file = os.path.join(dir_path, 'global_igbp_15s_2020.nc')\n",
    "#         mask_file = os.path.join(dir_path, 'mask_woody_veg.nc4')\n",
    "#         run_command(f\"cdo -f nc4 -z zip -setrtoc2,1,9,1,nan {igbp_file} {mask_file}\")\n",
    "#         print(\"mask_woody_veg completed\")\n",
    "\n",
    "#     def mask_shallow_bedrock() -> None:\n",
    "#         dir_path = os.path.join(path, 'masking_criteria')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         dtb_file = os.path.join(dir_path, 'average_soil_and_sedimentary-deposit_thickness_remap_cm.nc')\n",
    "#         output_interp = os.path.join(dir_path, 'dtb_interp.nc4')\n",
    "#         mask_file = os.path.join(dir_path, 'mask_shallow_bedrock.nc4')\n",
    "#         run_command(f\"gdalwarp -multi -wo NUM_THREADS=48 -ot Float32 -of netCDF -co FORMAT=NC4 -r bilinear -ts 86400 43200 -overwrite {dtb_file} {output_interp}\")\n",
    "#         run_command(f\"cdo -f nc4 -z zip -setrtoc2,0,150,1,nan {output_interp} {mask_file}\")\n",
    "#         print(\"mask_shallow_bedrock completed\")\n",
    "    \n",
    "#     mask_adequate_water()\n",
    "#     mask_woody_veg()\n",
    "#     mask_shallow_bedrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the Ssoil:\n",
    "1. calculate the DTB stratification (0~5~15~30~60~100~150 cm) to align the SAWS stratification (0~5~15~30~60~100~200 cm)\n",
    "2. use the vertical stratification (DTB and SAWS) to calculate the Ssoil\n",
    "\"\"\" \n",
    "# def Ssoil() -> None:\n",
    "#     layer = [0, 5, 15, 30, 60, 100, 150]\n",
    "#     dir_path = os.path.join(path, 'Ssoil')\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#     saws_path = os.path.join(dir_path, 'SAWS_Kosugi')\n",
    "#     ssoil_file = os.path.join(dir_path, f'Ssoil.nc4')\n",
    "\n",
    "#     def DTB_layer() -> None:\n",
    "#         dtb_file = os.path.join(dir_path, 'average_soil_and_sedimentary-deposit_thickness_remap_cm.nc')\n",
    "#         image = xr.open_dataset(dtb_file)\n",
    "#         s = image['Band1']\n",
    "#         for i in range(len(layer)-1):\n",
    "#             dtb_layer_file = os.path.join(dir_path, f'DTB_layer{i+1}.nc')\n",
    "#             delta_s = s - layer[i]\n",
    "#             delta_s = np.where(delta_s>(layer[i+1]-layer[i]), (layer[i+1]-layer[i]), delta_s)\n",
    "#             delta_s = np.where(delta_s<0, 0, delta_s)\n",
    "            \n",
    "#             shutil.copyfile(f'{saws_path}/saws{i+1}.nc', dtb_layer_file)\n",
    "#             with nc.Dataset(dtb_layer_file, 'a') as file:\n",
    "#                 s_var = file.variables['Band1']\n",
    "#                 s_var[:,:] = delta_s      \n",
    "#         print(\"DTB_layer completed\")\n",
    "\n",
    "#     DTB_layer()\n",
    "#     for i in range(len(layer)-1):\n",
    "#         dtb_layer_file = os.path.join(dir_path, f'DTB_layer{i+1}.nc')\n",
    "#         saws_layer_file = os.path.join(dir_path, f'saws{i+1}.nc')\n",
    "#         ssoil_layer_file = os.path.join(dir_path, f'Ssoil_layer{i+1}.nc4')\n",
    "#         run_command(f'ln -sf {saws_path}/saws{i+1}.nc {saws_layer_file}')\n",
    "#         run_command(f'cdo -f nc4 -z zip -mulc,10 -mul {saws_layer_file} {dtb_layer_file} {ssoil_layer_file}')\n",
    "#     filelist = [f'{dir_path}/Ssoil_layer{i+1}.nc4' for i in range(len(layer)-1)]\n",
    "#     filelistname = ' '.join(filelist)\n",
    "#     run_command(f'cdo -f nc4 -z zip -enssum {filelistname} {ssoil_file}')\n",
    "#     print(\"Ssoil completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31105aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate some other variables include:\n",
    "1. SnowCover: convert the snowcover(%) to if snow(>=10 -> 0 and <10 -> 1)\n",
    "2. IGBP: sel the time\n",
    "3. Koppen: translate the tif to nc4, and remaplaf from 1km to 500m\n",
    "4. area: calculate the area for 500m and 0p1\n",
    "5. DTB: calculate some DTB for different sources\n",
    "\"\"\"\n",
    "# def other():\n",
    "#     def SnowCover():\n",
    "#         # py_file = os.path.join('/stu01/xuxh22/Bedrock/preprocess/', 'pre_SC.py')\n",
    "#         # run_command(f'python {py_file}')\n",
    "#         dir_path = os.path.join(path, 'SC')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         sc_0p05_file = os.path.join(dir_path, 'SnowCover_0p05.nc')\n",
    "#         sc_0p1_file = os.path.join(dir_path, 'SnowCover_0p1.nc4')\n",
    "#         sc_0p1_mask_file = os.path.join(dir_path, 'SnowCover_0p1_mask.nc4')\n",
    "#         # The snow cover fraction should be kept at the same resolution as diff_3.nc of Sr and Dr Data, from 0.05° to 0.1°\n",
    "#         run_command(f\"gdalwarp -multi -wo NUM_THREADS=48 -ot Float32 -of netCDF -co FORMAT=NC4 -r bilinear -ts 3600 1800 -overwrite {sc_0p05_file} {sc_0p1_file}\")\n",
    "#         run_command(f'cdo -f nc4 -z zip -setrtoc2,10,100,0,1 {sc_0p1_file} {sc_0p1_mask_file}')\n",
    "#         print(\"SnowCover completed\")\n",
    "\n",
    "#     def IGBP():\n",
    "#         dir_path = os.path.join(path, 'IGBP')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         origin_file = os.path.join(dir_path, 'global_igbp_15s_2020.nc')\n",
    "#         igbp_file = os.path.join(dir_path, 'IGBP.nc4')\n",
    "#         run_command(f'cdo -f nc4 -z zip -seltimestep,1 {origin_file} {igbp_file}')\n",
    "#         print(\"IGBP completed\")\n",
    "\n",
    "#     def Koppen():\n",
    "#         dir_path = os.path.join(path, 'Koppen')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         origin_tif_file = os.path.join(dir_path, 'Beck_KG_V1_present_0p0083.tif')\n",
    "#         origin_nc4_file = os.path.join(dir_path, 'Beck_KG_V1_present_0p0083.nc4')\n",
    "#         remap_file = os.path.join(path, '500.txt')\n",
    "#         koppen_file = os.path.join(dir_path, 'Koppen.nc4')\n",
    "#         run_command(f\"gdal_translate -of netCDF -co FORMAT=NC4 -a_srs EPSG:4326 {origin_tif_file} {origin_nc4_file}\")\n",
    "#         run_command(f\"cdo -f nc4 -z zip -b I32 -P 48 --no_remap_weights remaplaf,{remap_file} {origin_nc4_file} {koppen_file}\")\n",
    "#         print(\"Koppen completed\")\n",
    "\n",
    "#     def area():\n",
    "#         dir_path = os.path.join(path, 'Area')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         data_file = os.path.join(path, 'diff', 'diff.nc')\n",
    "#         area_file = os.path.join(dir_path, 'Area.nc')\n",
    "#         # area_file = os.path.join(dir_path, 'Area_0p1.nc')\n",
    "\n",
    "#         def count_area(lat1,lat2):\n",
    "#             lat1,lat2 = map(math.radians,[lat1,lat2])\n",
    "#             r = 6.37122e6\n",
    "#             dlon = 0.00416666688397527\n",
    "#             # dlon = 0.1\n",
    "#             dlon_rad = math.radians(dlon)\n",
    "#             area = abs(r**2 * dlon_rad * (math.sin(lat2)-math.sin(lat1)))\n",
    "#             # print(area)\n",
    "#             return area\n",
    "\n",
    "#         data = xr.open_dataset(data_file)\n",
    "#         lat = data['lat']\n",
    "#         lon = data['lon']\n",
    "#         inc = 0.00416666688397527\n",
    "#         # inc = 0.1\n",
    "#         lat1 = lat-inc/2\n",
    "#         lat2 = lat+inc/2    \n",
    "#         grid1,grid2 = np.meshgrid(lon, lat)\n",
    "#         area = np.zeros_like(grid1)\n",
    "#         result = Parallel(n_jobs=12)(delayed(count_area)(lat1[i], lat2[i]) for i in range(len(lat)))\n",
    "#         for i in range(len(lat)):\n",
    "#             area[i, :] = result[i]\n",
    "#             print(area[i,0])\n",
    "#         print(f'The total area of the earth: {np.sum(area):.3f} $m^2$')\n",
    "                \n",
    "#         output_ds = xr.Dataset({'area': (('lat', 'lon'), area)},\n",
    "#                             coords={'lat': data['lat'], 'lon': data['lon']})\n",
    "#         print(area)\n",
    "#         print(f'The total area of the earth: {np.sum(area)/1e12:.3f} million $km^2$')\n",
    "#         output_ds.to_netcdf(area_file)\n",
    "#         print(\"Area completed\")\n",
    "\n",
    "#     def DTB():\n",
    "#         # Iowa measured data, the data is given by Shangguan et al.\n",
    "#         dir_path = os.path.join(path, 'DTB', 'DTB_Iowa')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         tif_file = os.path.join(dir_path, 'Iowa.tif')\n",
    "#         nc_file = os.path.join(dir_path, 'Iowa.nc4')\n",
    "#         run_command(f'gdal_translate -of netCDF -co FORMAT=NC4 -a_srs EPSG:4326 {tif_file} {nc_file}')\n",
    "        \n",
    "#         # Send the processed Soilgrids data cp over\n",
    "#         dir_path = os.path.join(path, 'DTB', 'DTB_Shangguan')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         tif_file = os.path.join(dir_path, 'BDTICM_M_250m_ll.tif')\n",
    "#         nc_file = os.path.join(dir_path, 'DTB_Shangguan.nc4')\n",
    "#         run_command(f\"gdalwarp -multi -wo NUM_THREADS=48 -ot Float32 -of netCDF -co FORMAT=NC4 -r bilinear -ts 86400 43200 -t_srs EPSG:4326 -te -180 -90 180 90 -overwrite {tif_file} {nc_file}\")\n",
    "        \n",
    "#         # gNATSGO bedrock data exported by GEE, 2 of which contains the Iowa region\n",
    "#         dir_path = os.path.join(path, 'DTB', 'DTB_gNATSGO')\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         gNATSGO_file = os.path.join(dir_path, 'DTB_gNATSGO.nc4')\n",
    "#         for i in range(8):\n",
    "#             tif_file = os.path.join(dir_path, f'Bedrock_US_gNATSGO_90m-{i+1}.tif')\n",
    "#             nc_file = os.path.join(dir_path, f'Bedrock_US_gNATSGO_90m-{i+1}.nc4')\n",
    "#             run_command(f'gdal_translate -of netCDF -co FORMAT=NC4 -a_srs EPSG:4326 {tif_file} {nc_file}')\n",
    "#         filelist = [f'{dir_path}/Bedrock_US_gNATSGO_90m-{i}.nc4' for i in range(5, 9)] + [f'{dir_path}Bedrock_US_gNATSGO_90m-{i}.nc4' for i in range(1, 5)]\n",
    "#         filelistname = ' '.join(filelist)\n",
    "#         run_command(f'cdo -f nc4 -z zip -collgrid {filelistname} {gNATSGO_file}')\n",
    "    \n",
    "#     SnowCover()\n",
    "#     IGBP()\n",
    "#     Koppen()\n",
    "#     area()\n",
    "#     DTB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93242da",
   "metadata": {},
   "source": [
    "## 2. Rolling calculate the first temporary Bedrock Water Storage Deficit and Root-zone Water Storage Deficit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c72b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(f'{data_path}diff.nc4') # ensemble mean ET - ensemble mean P, 8-day, 0p1, 2003.01.01-2020.12.31\n",
    "current_diff = ds['et']\n",
    "ds2 = xr.open_dataset(f'{data_path}SnowCover.nc4') # snowcover>10 -> 0, snowcover<=10 -> 1, 8-day, 0p1,  2003.01.01-2020.12.31\n",
    "snowf = ds2['snowf']\n",
    "ds3 = xr.open_dataset(f'{data_path}Ssoil_0p1.nc4') # soil water storage capacity, 0p1\n",
    "ssoil = ds3['Band1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10e77b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'time' (time: 18)>\n",
      "array(['2003-01-01T00:00:00.000000000', '2004-01-01T00:00:00.000000000',\n",
      "       '2005-01-01T00:00:00.000000000', '2006-01-01T00:00:00.000000000',\n",
      "       '2007-01-01T00:00:00.000000000', '2008-01-01T00:00:00.000000000',\n",
      "       '2009-01-01T00:00:00.000000000', '2010-01-01T00:00:00.000000000',\n",
      "       '2011-01-01T00:00:00.000000000', '2012-01-01T00:00:00.000000000',\n",
      "       '2013-01-01T00:00:00.000000000', '2014-01-01T00:00:00.000000000',\n",
      "       '2015-01-01T00:00:00.000000000', '2016-01-01T00:00:00.000000000',\n",
      "       '2017-01-01T00:00:00.000000000', '2018-01-01T00:00:00.000000000',\n",
      "       '2019-01-01T00:00:00.000000000', '2020-01-01T00:00:00.000000000'],\n",
      "      dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2003-01-01 2004-01-01 ... 2020-01-01\n",
      "Attributes:\n",
      "    standard_name:  time\n",
      "    axis:           T\n"
     ]
    }
   ],
   "source": [
    "# Set the annual data format \n",
    "years = pd.date_range(start='2003-01-01', end='2020-01-01', freq='YS')\n",
    "\n",
    "time_array = xr.DataArray(\n",
    "    years,\n",
    "    dims=['time'],\n",
    "    coords={'time': years},\n",
    "    name='time',\n",
    "    attrs={\n",
    "        'standard_name': 'time',\n",
    "        'axis': 'T'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(time_array)\n",
    "\n",
    "# Obtain shape\n",
    "shape = current_diff.isel(time=0).shape\n",
    "time_len = len(ds.time) # 828"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0671dbb0",
   "metadata": {},
   "source": [
    "### 2.1 Annual Water Storage Deficit Method\n",
    "### Calculate the Dr (the annual root-zone water storgae deficit), Dbedrock (the annual bedrock water storage deficit), D_time (the time state: frequency, duration, initial day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de49f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "dr = np.zeros((18, *shape))\n",
    "dbedrock = np.zeros((18, *shape))\n",
    "\n",
    "use_dbedrock_frequency_per_year = np.zeros((18, *shape))\n",
    "use_dbedrock_duration_per_year = np.zeros((18,*shape))\n",
    "use_dbedrock_first_day = np.zeros((18,*shape))\n",
    "\n",
    "use_dbedrock_sum_frequency = np.zeros(shape)\n",
    "use_dbedrock_sum_duration = np.zeros(shape)\n",
    "\n",
    "use_dbedrock_mean_duration_per_use = np.zeros(shape)\n",
    "use_dbedrock_max_duration_per_use = np.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Dbedrock,Y and related time statistics\n",
    "for j in range(18):\n",
    "    print(f\"year is {j+2003}\")\n",
    "\n",
    "    # Initialize variables\n",
    "    current_cwd = np.zeros(shape) \n",
    "    use_dbedrock_duration_per_use = np.zeros(shape)\n",
    "\n",
    "    # Loop through time indices for the current year (46 8-days periods per year)\n",
    "    for i in range(0+46*j,46+46*j):\n",
    "        print(f\"Processing time index: {i}\")\n",
    "        # Calculate start and end days for the period, adjusting for leap years\n",
    "        day_stt = 8*(i-46*j)+1\n",
    "        day_end = 8*(i-46*j)+1+\\\n",
    "            ((5 if ((j + 2003) % 4 == 0 and ((j + 2003) % 100 != 0 or (j + 2003) % 400 == 0)) else 4)\\\n",
    "            if (i+1) % 46 == 0 else 7)\n",
    "        day_duration = day_end-day_stt+1\n",
    "        print(f\"the period {i-46*j+1:3} day from {day_stt:4} to {day_end:4}\")\n",
    "        print(f\"the period {i-46*j+1:3} day is {day_duration:1}\")\n",
    "\n",
    "        # Calculate current delta_tn, cwd and sr\n",
    "        current_delta_tn = current_diff.isel(time=i).values * snowf.isel(time=i).values\n",
    "        last_cwd = current_cwd\n",
    "        current_cwd = np.where(current_delta_tn >= 0, current_cwd + current_delta_tn, 0)\n",
    "        dr[j,:,:] = np.maximum(dr[j,:,:], current_cwd)\n",
    "\n",
    "        # Calculate the first day, duration and all time periods of using bedrock water  \n",
    "        mask1 = current_cwd > ssoil\n",
    "        mask2 = last_cwd > ssoil\n",
    "        mask3 = last_cwd <= ssoil\n",
    "\n",
    "        use_dbedrock_frequency_per_year[j,:,:] = np.where(mask1 & mask3, use_dbedrock_frequency_per_year[j,:,:]+1, use_dbedrock_frequency_per_year[j,:,:])\n",
    "        use_dbedrock_duration_per_year [j,:,:] = np.where(mask1, use_dbedrock_duration_per_year[j,:,:]+day_duration, use_dbedrock_duration_per_year[j,:,:])\n",
    "        use_dbedrock_first_day[j,:,:] = np.where(mask1 & (use_dbedrock_first_day[j,:,:] == 0), day_stt, use_dbedrock_first_day[j,:,:])\n",
    "\n",
    "        use_dbedrock_sum_frequency = np.where(mask1 & mask3, use_dbedrock_sum_frequency+1, use_dbedrock_sum_frequency)\n",
    "        use_dbedrock_sum_duration = np.where(mask1, use_dbedrock_sum_duration + day_duration, use_dbedrock_sum_duration)\n",
    "\n",
    "        use_dbedrock_duration_per_use = np.where(mask1, use_dbedrock_duration_per_use + day_duration, 0)\n",
    "        use_dbedrock_max_duration_per_use = np.where(use_dbedrock_duration_per_use>use_dbedrock_max_duration_per_use, use_dbedrock_duration_per_use, use_dbedrock_max_duration_per_use)\n",
    "\n",
    "    dbedrock[j,:,:] = np.where(dr[j,:,:] > ssoil, dr[j,:,:] - ssoil, 0)\n",
    "use_dbedrock_mean_duration_per_use = np.where(use_dbedrock_sum_frequency > 0, \n",
    "                                                np.divide(use_dbedrock_sum_duration, use_dbedrock_sum_frequency, where=use_dbedrock_sum_frequency > 0)\n",
    "                                                , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates upfront\n",
    "coords = {'lat': ds['lat'], 'lon': ds['lon']}\n",
    "time_coords = {'time': time_array, 'lat': ds['lat'], 'lon': ds['lon']}\n",
    "\n",
    "# Define datasets and their metadata\n",
    "datasets = [\n",
    "    # Annual data\n",
    "    {'name': 'Dr', 'data': dr, 'dims': ('lat', 'lon'), 'years': range(2003, 2021), 'file_prefix': 'Dr'},\n",
    "    {'name': 'Dbedrock', 'data': dbedrock, 'dims': ('lat', 'lon'), 'years': range(2003, 2021), 'file_prefix': 'Dbedrock'},\n",
    "    # Aggregate data\n",
    "    {'name': 'Duration', 'data': use_dbedrock_max_duration_per_use, 'dims': ('lat', 'lon'), 'file_prefix': 'D_max_duration_per_use'},\n",
    "    {'name': 'Duration', 'data': use_dbedrock_mean_duration_per_use, 'dims': ('lat', 'lon'), 'file_prefix': 'D_mean_duration_per_use'},\n",
    "    {'name': 'Frequency', 'data': use_dbedrock_sum_frequency, 'dims': ('lat', 'lon'), 'file_prefix': 'D_sum_frequency'},\n",
    "    {'name': 'Duration', 'data': use_dbedrock_sum_duration, 'dims': ('lat', 'lon'), 'file_prefix': 'D_sum_duration'},\n",
    "    # Per-year data\n",
    "    {'name': 'Frequency', 'data': use_dbedrock_frequency_per_year, 'dims': ('time', 'lat', 'lon'), 'file_prefix': 'D_frequency_per_year', 'coords': time_coords},\n",
    "    {'name': 'Duration', 'data': use_dbedrock_duration_per_year, 'dims': ('time', 'lat', 'lon'), 'file_prefix': 'D_duration_per_year', 'coords': time_coords},\n",
    "    {'name': 'First_Day', 'data': use_dbedrock_first_day, 'dims': ('time', 'lat', 'lon'), 'file_prefix': 'D_first_day', 'coords': time_coords},\n",
    "]\n",
    "\n",
    "D_time_path = os.path.join(data_path, 'D_time')\n",
    "\n",
    "for ds_info in datasets:\n",
    "    try:\n",
    "        data = ds_info['data']\n",
    "        name = ds_info['name']\n",
    "        dims = ds_info['dims']\n",
    "        file_prefix = ds_info['file_prefix']\n",
    "        ds_coords = ds_info.get('coords', coords)  # Default to lat/lon coordinates\n",
    "\n",
    "        if 'years' in ds_info:  # Process annual data\n",
    "            for i, year in enumerate(ds_info['years']):\n",
    "                output_ds = xr.Dataset({name: (dims, data[i, :, :])},\n",
    "                                      coords=ds_coords)\n",
    "                output_ds.to_netcdf(f'{D_time_path}{file_prefix}_{year}_tmp1.nc4')\n",
    "        else:  # Process aggregate data\n",
    "            output_ds = xr.Dataset({name: (dims, data)},\n",
    "                                  coords=ds_coords)\n",
    "            output_ds.to_netcdf(f'{D_time_path}{file_prefix}_tmp1.nc4')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {file_prefix}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1caa58",
   "metadata": {},
   "source": [
    "### 2.2 Non-Reset Cumulative Water Storage Capacity Method \n",
    "### Calculate the Sr (the root-zone water storgae), Sbedrock (the bedrock water storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "current_cwd = np.zeros(shape) \n",
    "sr = np.zeros(shape)\n",
    "sbedrock = np.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the water balance from 2003 to 2020\n",
    "for i in range(time_len):\n",
    "    print(f\"Processing time index: {i}\")\n",
    "    day_stt = 8*i+1-3*(i//46)+((i//46)+2)//4\n",
    "    day_end = 8*(i+1)+1-3*((i+1)//46)+(((i+1)//46)+2)//4-1\n",
    "    day_duration = day_end-day_stt+1\n",
    "    j = i//46\n",
    "    year = j+2003\n",
    "    print(year)\n",
    "    print(f\"the period {i+1:3} day from {day_stt:4} to {day_end:4}\")\n",
    "    print(f\"the period {i+1:3} day is {day_duration:1}\")\n",
    "\n",
    "    # Calculate current delta_tn, cwd and sr\n",
    "    current_delta_tn = current_diff.isel(time=i).values * snowf.isel(time=i).values\n",
    "    last_cwd = current_cwd\n",
    "    current_cwd = np.where(current_delta_tn >= 0, current_cwd + current_delta_tn, 0)\n",
    "    sr = np.maximum(sr, current_cwd)\n",
    "\n",
    "sbedrock = np.where(sr > ssoil, sr - ssoil, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to the first temporary NetCDF files\n",
    "output_ds = xr.Dataset({'Sr': (('lat', 'lon'), sr)},\n",
    "                    coords={'lat': ds['lat'], 'lon': ds['lon']})\n",
    "output_ds.to_netcdf(f'{data_path}Sr_tmp1.nc4')\n",
    "\n",
    "output_ds1 = xr.Dataset({'Sbedrock': (('lat', 'lon'), sbedrock)},\n",
    "                    coords={'lat': ds['lat'], 'lon': ds['lon']})\n",
    "output_ds1.to_netcdf(f'{data_path}Sbedrock_tmp1.nc4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bb0b5",
   "metadata": {},
   "source": [
    "## 3. Data Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca609a5",
   "metadata": {},
   "source": [
    "### 3.1 Calculate the last masking criteria: max(Dbedrock) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca74696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_Dbedrock_max():\n",
    "    name_list = 'cdo -O -ensmax '\n",
    "    for year in range(2003,2021):\n",
    "        name = f'{D_time_path}Dbedrock_{year}_tmp1.nc4'\n",
    "        name_list = name_list+' '+name\n",
    "    output_file = f'{data_path}Dbedrock_max_tmp1.nc4'\n",
    "    print(name_list+' '+output_file)\n",
    "    os.system(name_list+' '+output_file)\n",
    "\n",
    "    subprocess.run(f\"cdo -b F32 -P 48 --no_remap_weights remapbil,{data_path}{resolution}.txt {data_path}Dbedrock_max_tmp1.nc4 {data_path}Dbedrock_max_tmp2.nc4\", shell=True, check=True)\n",
    "    run_command(f\"cdo -O -f nc4 -z zip -setrtoc2,-inf,1e-1,nan,1 {data_path}Dbedrock_max_tmp2.nc4 {mask_path}mask_Dbedrock_gt_0.nc4\")\n",
    "\n",
    "def mask_combine():\n",
    "    \"\"\"Combine the mask files for different criteria into one file\n",
    "    \"\"\"\n",
    "    mask_files = [\n",
    "        f'{mask_path}mask_adequate_water.nc4',\n",
    "        f'{mask_path}mask_woody_veg.nc4',\n",
    "        f'{mask_path}mask_shallow_bedrock.nc4',     \n",
    "        f'{mask_path}mask_Dbedrock_gt_0.nc4']\n",
    "\n",
    "    run_command(f\"cdo -O mul {mask_files[0]} {mask_files[1]} {mask_path}mask_combine_12.nc4\")\n",
    "    run_command(f\"cdo -O mul {mask_path}mask_combine_12.nc4 {mask_files[2]} {mask_path}mask_combine_123.nc4\")\n",
    "    run_command(f\"cdo -O mul {mask_path}mask_combine_123.nc4 {mask_files[3]} {mask_path}mask_combine_all.nc4\")\n",
    "\n",
    "dp_Dbedrock_max()\n",
    "mask_combine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c484d0",
   "metadata": {},
   "source": [
    "### 3.2 Postprocess for Dbedrock, Dr, and D time state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac833ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cdo function to use parallel operations \n",
    "def cdo_mul(filename1, filename2, filename3):\n",
    "    subprocess.run(f\"cdo mul {filename1} {filename2} {filename3}\", shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf427c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_Dr():\n",
    "    # remap the 0p1 resolution to 0p1 resolution(no need, but for the sake of formatting consistency)\n",
    "    for j in range(18):\n",
    "        print(f\"year is {j+2003}\")\n",
    "        subprocess.run(f\"cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}Dr_{2003+j}_tmp1.nc4 {D_time_path}Dr_{2003+j}_tmp2.nc4\", shell=True, check=True)\n",
    "    Parallel(n_jobs=5)(delayed(cdo_mul)(f\"{D_time_path}Dr_{2003+j}_tmp2.nc4\", f\"{mask_path}mask_combine_all.nc4\", f\"{D_time_path}Dr_{2003+j}.nc4\") for j in tqdm(range(18)))\n",
    "\n",
    "def dp_Dbedrock():\n",
    "    # remap the 0p1 resolution to 0p1 resolution(no need, but for the sake of formatting consistency)\n",
    "    for j in range(18):\n",
    "        print(f\"year is {j+2003}\")\n",
    "        subprocess.run(f\"cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}Dbedrock_{2003+j}_tmp1.nc4 {D_time_path}Dbedrock_{2003+j}_tmp2.nc4\", shell=True, check=True)\n",
    "\n",
    "    Parallel(n_jobs=5)(delayed(cdo_mul)(f\"{D_time_path}Dbedrock_{2003+j}_tmp2.nc4\", f\"{mask_path}mask_combine_all.nc4\", f\"{D_time_path}Dbedrock_{2003+j}.nc4\") for j in tqdm(range(18)))\n",
    "\n",
    "dp_Dr()\n",
    "dp_Dbedrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_Dbedrock_Frequency():\n",
    "    # calculate Dbedrock Frequency\n",
    "    s1 = 0\n",
    "    for year in range(2003,2021):\n",
    "        file = f'{D_time_path}Dbedrock_{year}_tmp2.nc4'\n",
    "        image = xr.open_dataset(file)\n",
    "        s = image['Dbedrock']\n",
    "\n",
    "        print(f'year: {year}, min: {s.min().values}, max: {s.max().values}')\n",
    "        \n",
    "        s = np.where(s > 0, 2, np.where(s < 0, 1, 0))\n",
    "        print(f'year: {year}, min: {s.min()}, max: {s.max()}')\n",
    "        \n",
    "        print(s.min(),s.max())\n",
    "        \n",
    "        if year == 2003:\n",
    "            s1 = s\n",
    "        else:\n",
    "            s1 = s*s1\n",
    "        \n",
    "        s_nonan = np.where((s1<0), 0, s1)\n",
    "        print(s1.min(),s1.max(),np.mean(s_nonan))\n",
    "        image.close()\n",
    "    print('end do')\n",
    "\n",
    "    s1 = np.where((s1 >=2) & (s1 < 262144), 2, s1)\n",
    "    s1 = np.where((s1 == 1), 3, s1)\n",
    "    s1 = np.where(s1==262144, 1, s1)\n",
    "\n",
    "    file_mask = f'{mask_path}mask_combine_12.nc4'\n",
    "    mask = xr.open_dataset(file_mask)\n",
    "    s2 = mask['Band1']\n",
    "    print(s1.min(),s1.max())\n",
    "\n",
    "    s1 = np.where((s1==0) & (s2 == 1), 4, s1)\n",
    "\n",
    "    print(s1.min(),s1.max())\n",
    "    shutil.copyfile(f'{D_time_path}Dbedrock_2003.nc4', f'{data_path}Dbedrock_Frequency_tmp1.nc4')\n",
    "\n",
    "    with nc.Dataset(f'{data_path}Dbedrock_Frequency_tmp1.nc4', 'a') as file:\n",
    "        s_var = file.variables['Dbedrock']\n",
    "        new_s_data = s1 \n",
    "        s_var[:,:] = new_s_data\n",
    "\n",
    "    os.system(f'cdo mul {data_path}Dbedrock_Frequency_tmp1.nc4 {mask_path}mask_combine_all.nc4 {data_path}Dbedrock_Frequency.nc4')\n",
    "\n",
    "dp_Dbedrock_Frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_frequency_per_year():\n",
    "    os.system(f'cdo -setrtoc,-0.5,0.5,nan {D_time_path}D_frequency_per_year_tmp1.nc4 {D_time_path}D_frequency_per_year_set0_to_nan_tmp1.nc4')\n",
    "    os.system(f'cdo timmean {D_time_path}D_frequency_per_year_set0_to_nan_tmp1.nc4 {D_time_path}D_frequency_per_year_mean_tmp1.nc4')\n",
    "    os.system(f'cdo timmax {D_time_path}D_frequency_per_year_set0_to_nan_tmp1.nc4 {D_time_path}D_frequency_per_year_max_tmp1.nc4')\n",
    "\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_frequency_per_year_mean_tmp1.nc4 {D_time_path}D_frequency_per_year_mean_tmp2.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_frequency_per_year_mean_tmp2.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_frequency_per_year_mean.nc4\")\n",
    "\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_frequency_per_year_max_tmp1.nc4 {D_time_path}D_frequency_per_year_max_tmp2.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_frequency_per_year_max_tmp2.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_frequency_per_year_max.nc4\")\n",
    "\n",
    "\n",
    "def dp_sum_frequency():\n",
    "    os.system(f'cdo -setrtoc,-0.5,0.5,nan {D_time_path}D_sum_frequency_tmp1.nc4 {D_time_path}D_sum_frequency_tmp2.nc4')\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_sum_frequency_tmp2.nc4 {D_time_path}D_sum_frequency_tmp3.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_sum_frequency_tmp3.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_sum_frequency.nc4\")\n",
    "\n",
    "def dp_duration_per_year():\n",
    "    os.system(f'cdo -setrtoc,-0.5,0.5,nan {D_time_path}D_duration_per_year_tmp1.nc4 {D_time_path}D_duration_per_year_set0_to_nan_tmp1.nc4')\n",
    "    os.system(f'cdo timmean {D_time_path}D_duration_per_year_set0_to_nan_tmp1.nc4 {D_time_path}D_duration_per_year_mean_tmp1.nc4')\n",
    "    os.system(f'cdo timmax {D_time_path}D_duration_per_year_set0_to_nan_tmp1.nc4 {D_time_path}D_duration_per_year_max_tmp1.nc4')\n",
    "\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_duration_per_year_mean_tmp1.nc4 {D_time_path}D_duration_per_year_mean_tmp2.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_duration_per_year_mean_tmp2.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_duration_per_year_mean.nc4\")\n",
    "\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_duration_per_year_max_tmp1.nc4 {D_time_path}D_duration_per_year_max_tmp2.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_duration_per_year_max_tmp2.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_duration_per_year_max.nc4\")\n",
    "\n",
    "def dp_duration_per_use():\n",
    "    os.system(f'cdo -setrtoc,-0.5,0.5,nan {D_time_path}D_duration_per_use_max_tmp1.nc4 {D_time_path}D_duration_per_use_max_tmp2.nc4')\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_duration_per_use_max_tmp2.nc4 {D_time_path}D_duration_per_use_max_tmp3.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_duration_per_use_max_tmp3.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_duration_per_use_max.nc4\")\n",
    "\n",
    "    os.system(f'cdo -setrtoc,-0.5,0.5,nan {D_time_path}D_duration_per_use_mean_tmp1.nc4 {D_time_path}D_duration_per_use_mean_tmp2.nc4')\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_duration_per_use_mean_tmp2.nc4 {D_time_path}D_duration_per_use_mean_tmp3.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_duration_per_use_mean_tmp3.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_duration_per_use_mean.nc4\")\n",
    "\n",
    "def dp_sum_duration():\n",
    "    os.system(f'cdo -setrtoc,-0.5,0.5,nan {D_time_path}D_sum_duration_tmp1.nc4 {D_time_path}D_sum_duration_tmp2.nc4')\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_sum_duration_tmp2.nc4 {D_time_path}D_sum_duration_tmp3.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_sum_duration_tmp3.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_sum_duration.nc4\")\n",
    "\n",
    "def dp_first_day():\n",
    "    os.system(f'cdo -setrtoc,-0.5,0.5,nan {D_time_path}D_first_day_tmp1.nc4 {D_time_path}D_first_day_set0_to_nan_tmp1.nc4')\n",
    "    os.system(f'cdo timmax {D_time_path}D_first_day_set0_to_nan_tmp1.nc4 {D_time_path}D_first_day_max_tmp1.nc4')\n",
    "    os.system(f'cdo timmin {D_time_path}D_first_day_set0_to_nan_tmp1.nc4 {D_time_path}D_first_day_min_tmp1.nc4')\n",
    "    os.system(f'cdo sub {D_time_path}D_first_day_max_tmp1.nc4 {D_time_path}D_first_day_min_tmp1.nc4 {D_time_path}D_first_day_max_sub_min_tmp1.nc4')\n",
    "\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_first_day_min_tmp1.nc4 {D_time_path}D_first_day_min_tmp2.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_first_day_min_tmp2.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_first_day_min.nc4\")\n",
    "\n",
    "    os.system(f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt {D_time_path}D_first_day_max_sub_min_tmp1.nc4 {D_time_path}D_first_day_max_sub_min_tmp2.nc4')\n",
    "    os.system(f\"cdo mul {D_time_path}D_first_day_max_sub_min_tmp2.nc4 {mask_path}mask_combine_all.nc4 {D_time_path}D_first_day_max_sub_min.nc4\")\n",
    "\n",
    "dp_frequency_per_year()\n",
    "dp_sum_frequency()\n",
    "dp_duration_per_year()\n",
    "dp_duration_per_use()\n",
    "dp_sum_duration()\n",
    "dp_first_day()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a1f97",
   "metadata": {},
   "source": [
    "### 3.3 Postprocess for Sbedrock and Sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remap_command = f'cdo -f nc4 -z zip -b F32 -P 48 --no_remap_weights -remapbil,{data_path}{resolution}.txt'\n",
    "\n",
    "def dp_Sbedrock():\n",
    "    os.system(f\"{remap_command} {data_path}Sbedrock_tmp1.nc4 {data_path}Sbedrock_tmp2.nc4\")\n",
    "    os.system(f\"cdo mul {data_path}Sbedrock_tmp2.nc4 {mask_path}mask_combine_all.nc4 {data_path}Sbedrock.nc4\")\n",
    "    print(f'The Sbedrock has finished')  \n",
    "\n",
    "def dp_Sr():\n",
    "    os.system(f'{remap_command} {data_path}Sr_tmp1.nc4 {data_path}Sr_tmp2.nc4')\n",
    "    os.system(f\"cdo mul {data_path}Sr_tmp2.nc4 {mask_path}mask_combine_all.nc4 {data_path}Sr.nc4\")\n",
    "    print(f'The Sr has finished')    \n",
    "\n",
    "dp_Sbedrock()\n",
    "dp_Sr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
