{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a3c9c8b",
   "metadata": {},
   "source": [
    "### 1. Calculate the water balance method (entire_period from 2003.01.01-2020.12.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd416db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time range: 2003-01-01 00:00:00 to 2020-12-26 00:00:00\n",
      "Processing 0/827\n",
      "Processing 10/827\n",
      "Processing 20/827\n",
      "Processing 30/827\n",
      "Processing 40/827\n",
      "Processing 50/827\n",
      "Processing 60/827\n",
      "Processing 70/827\n",
      "Processing 80/827\n",
      "Processing 90/827\n",
      "Processing 100/827\n",
      "Processing 110/827\n",
      "Processing 120/827\n",
      "Processing 130/827\n",
      "Processing 140/827\n",
      "Processing 150/827\n",
      "Processing 160/827\n",
      "Processing 170/827\n",
      "Processing 180/827\n",
      "Processing 190/827\n",
      "Processing 200/827\n",
      "Processing 210/827\n",
      "Processing 220/827\n",
      "Processing 230/827\n",
      "Processing 240/827\n",
      "Processing 250/827\n",
      "Processing 260/827\n",
      "Processing 270/827\n",
      "Processing 280/827\n",
      "Processing 290/827\n",
      "Processing 300/827\n",
      "Processing 310/827\n",
      "Processing 320/827\n",
      "Processing 330/827\n",
      "Processing 340/827\n",
      "Processing 350/827\n",
      "Processing 360/827\n",
      "Processing 370/827\n",
      "Processing 380/827\n",
      "Processing 390/827\n",
      "Processing 400/827\n",
      "Processing 410/827\n",
      "Processing 420/827\n",
      "Processing 430/827\n",
      "Processing 440/827\n",
      "Processing 450/827\n",
      "Processing 460/827\n",
      "Processing 470/827\n",
      "Processing 480/827\n",
      "Processing 490/827\n",
      "Processing 500/827\n",
      "Processing 510/827\n",
      "Processing 520/827\n",
      "Processing 530/827\n",
      "Processing 540/827\n",
      "Processing 550/827\n",
      "Processing 560/827\n",
      "Processing 570/827\n",
      "Processing 580/827\n",
      "Processing 590/827\n",
      "Processing 600/827\n",
      "Processing 610/827\n",
      "Processing 620/827\n",
      "Processing 630/827\n",
      "Processing 640/827\n",
      "Processing 650/827\n",
      "Processing 660/827\n",
      "Processing 670/827\n",
      "Processing 680/827\n",
      "Processing 690/827\n",
      "Processing 700/827\n",
      "Processing 710/827\n",
      "Processing 720/827\n",
      "Processing 730/827\n",
      "Processing 740/827\n",
      "Processing 750/827\n",
      "Processing 760/827\n",
      "Processing 770/827\n",
      "Processing 780/827\n",
      "Processing 790/827\n",
      "Processing 800/827\n",
      "Processing 810/827\n",
      "Processing 820/827\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset, date2num\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ROOT_DIR = (NOTEBOOK_DIR / \"../data\").resolve()\n",
    "RUN_DIR  = ROOT_DIR / \"run\"\n",
    "OUT_DIR = RUN_DIR / \"entire_period\"\n",
    "RES = \"p05\"\n",
    "\n",
    "ds  = xr.open_dataset(RUN_DIR / \"diff.nc\")\n",
    "ds2 = xr.open_dataset(ROOT_DIR / \"SC/SC.nc\")\n",
    "ds3 = xr.open_dataset(RUN_DIR / f\"Ssoil_{RES}.nc\")\n",
    "\n",
    "diff  = ds[\"diff\"]\n",
    "sc    = ds2[\"SC\"]\n",
    "ssoil = ds3[\"Ssoil\"]\n",
    "\n",
    "time_len = diff.sizes[\"time\"]\n",
    "nlat     = diff.sizes[\"lat\"]\n",
    "nlon     = diff.sizes[\"lon\"]\n",
    "\n",
    "cwd_i = np.zeros((nlat, nlon), dtype=np.float32)\n",
    "sr    = np.zeros((nlat, nlon), dtype=np.float32)\n",
    "\n",
    "out_nc = RUN_DIR / \"CWD.nc\"\n",
    "\n",
    "# time encoding\n",
    "time_dt   = pd.to_datetime(ds[\"time\"].values).to_pydatetime()\n",
    "print(\"Time range:\", time_dt[0], \"to\", time_dt[-1])\n",
    "time_unit = \"days since 1970-01-01 00:00:00\"\n",
    "time_cal  = \"proleptic_gregorian\"\n",
    "time_num  = date2num(time_dt, units=time_unit, calendar=time_cal)\n",
    "\n",
    "# choose output chunk sizes (tune)\n",
    "chunk_t, chunk_y, chunk_x = 1, 1200, 1200  # try 400-800\n",
    "\n",
    "with Dataset(out_nc, \"w\", format=\"NETCDF4\") as nc:\n",
    "    nc.createDimension(\"time\", time_len)\n",
    "    nc.createDimension(\"lat\",  nlat)\n",
    "    nc.createDimension(\"lon\",  nlon)\n",
    "\n",
    "    vtime = nc.createVariable(\"time\", \"f8\", (\"time\",))\n",
    "    vtime.units = time_unit\n",
    "    vtime.calendar = time_cal\n",
    "    vtime[:] = time_num\n",
    "\n",
    "    vlon = nc.createVariable(\"lon\", \"f4\", (\"lon\",))\n",
    "    vlon.units = \"degrees_east\"\n",
    "    vlon[:] = ds[\"lon\"].values.astype(np.float32)\n",
    "\n",
    "    vlat = nc.createVariable(\"lat\", \"f4\", (\"lat\",))\n",
    "    vlat.units = \"degrees_north\"\n",
    "    vlat[:] = ds[\"lat\"].values.astype(np.float32)\n",
    "\n",
    "    vCWD = nc.createVariable(\n",
    "        \"CWD\", \"f4\", (\"time\", \"lat\", \"lon\"),\n",
    "        zlib=True, complevel=3, shuffle=True,\n",
    "        chunksizes=(chunk_t, chunk_y, chunk_x),\n",
    "        fill_value=np.float32(np.nan)\n",
    "    )\n",
    "    vCWD.long_name = \"Cumulative Water Deficit (8-day running state)\"\n",
    "\n",
    "    for i in range(time_len):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing {i}/{time_len-1}\")\n",
    "\n",
    "        diff_i = diff.isel(time=i).values.astype(np.float32)\n",
    "        sc_i   = sc.isel(time=i).values.astype(np.float32)\n",
    "\n",
    "        delta_tn_i = diff_i * sc_i\n",
    "        cwd_i = np.where(delta_tn_i >= 0, cwd_i + delta_tn_i, 0.0).astype(np.float32)\n",
    "        sr = np.maximum(sr, cwd_i)\n",
    "\n",
    "        vCWD[i, :, :] = cwd_i  # stream write\n",
    "\n",
    "# final Sr/Sbedrock (small 2D outputs)\n",
    "ssoil  = ssoil.values.astype(np.float32)\n",
    "sbedrock  = np.where(sr > ssoil, sr - ssoil, 0.0).astype(np.float32)\n",
    "\n",
    "xr.Dataset({\"Sr\": ((\"lat\",\"lon\"), sr)}, coords={\"lat\": ds[\"lat\"], \"lon\": ds[\"lon\"]}) \\\n",
    "  .to_netcdf(OUT_DIR / \"Sr.nc\")\n",
    "\n",
    "xr.Dataset({\"Sbedrock\": ((\"lat\",\"lon\"), sbedrock)}, coords={\"lat\": ds[\"lat\"], \"lon\": ds[\"lon\"]}) \\\n",
    "  .to_netcdf(OUT_DIR / \"Sbedrock.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d6744",
   "metadata": {},
   "source": [
    "### 2. Calculate the water balance method (reset_annual from 2003.01.01-2003.12.31 ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b531c45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time range: 2003-01-01 00:00:00 to 2020-12-26 00:00:00 len= 828\n",
      "Years: 2003 -> 2020 N= 18\n",
      "Shape: (828, 3600, 7200)\n",
      "Processing 0/827  (year=2003)\n",
      "Processing 10/827  (year=2003)\n",
      "Processing 20/827  (year=2003)\n",
      "Processing 30/827  (year=2003)\n",
      "Processing 40/827  (year=2003)\n",
      "[YEAR OUT] 2003 -> Dr_2003.nc, Dbedrock_2003.nc\n",
      "Processing 50/827  (year=2004)\n",
      "Processing 60/827  (year=2004)\n",
      "Processing 70/827  (year=2004)\n",
      "Processing 80/827  (year=2004)\n",
      "Processing 90/827  (year=2004)\n",
      "[YEAR OUT] 2004 -> Dr_2004.nc, Dbedrock_2004.nc\n",
      "Processing 100/827  (year=2005)\n",
      "Processing 110/827  (year=2005)\n",
      "Processing 120/827  (year=2005)\n",
      "Processing 130/827  (year=2005)\n",
      "[YEAR OUT] 2005 -> Dr_2005.nc, Dbedrock_2005.nc\n",
      "Processing 140/827  (year=2006)\n",
      "Processing 150/827  (year=2006)\n",
      "Processing 160/827  (year=2006)\n",
      "Processing 170/827  (year=2006)\n",
      "Processing 180/827  (year=2006)\n",
      "[YEAR OUT] 2006 -> Dr_2006.nc, Dbedrock_2006.nc\n",
      "Processing 190/827  (year=2007)\n",
      "Processing 200/827  (year=2007)\n",
      "Processing 210/827  (year=2007)\n",
      "Processing 220/827  (year=2007)\n",
      "[YEAR OUT] 2007 -> Dr_2007.nc, Dbedrock_2007.nc\n",
      "Processing 230/827  (year=2008)\n",
      "Processing 240/827  (year=2008)\n",
      "Processing 250/827  (year=2008)\n",
      "Processing 260/827  (year=2008)\n",
      "Processing 270/827  (year=2008)\n",
      "[YEAR OUT] 2008 -> Dr_2008.nc, Dbedrock_2008.nc\n",
      "Processing 280/827  (year=2009)\n",
      "Processing 290/827  (year=2009)\n",
      "Processing 300/827  (year=2009)\n",
      "Processing 310/827  (year=2009)\n",
      "Processing 320/827  (year=2009)\n",
      "[YEAR OUT] 2009 -> Dr_2009.nc, Dbedrock_2009.nc\n",
      "Processing 330/827  (year=2010)\n",
      "Processing 340/827  (year=2010)\n",
      "Processing 350/827  (year=2010)\n",
      "Processing 360/827  (year=2010)\n",
      "[YEAR OUT] 2010 -> Dr_2010.nc, Dbedrock_2010.nc\n",
      "Processing 370/827  (year=2011)\n",
      "Processing 380/827  (year=2011)\n",
      "Processing 390/827  (year=2011)\n",
      "Processing 400/827  (year=2011)\n",
      "Processing 410/827  (year=2011)\n",
      "[YEAR OUT] 2011 -> Dr_2011.nc, Dbedrock_2011.nc\n",
      "Processing 420/827  (year=2012)\n",
      "Processing 430/827  (year=2012)\n",
      "Processing 440/827  (year=2012)\n",
      "Processing 450/827  (year=2012)\n",
      "[YEAR OUT] 2012 -> Dr_2012.nc, Dbedrock_2012.nc\n",
      "Processing 460/827  (year=2013)\n",
      "Processing 470/827  (year=2013)\n",
      "Processing 480/827  (year=2013)\n",
      "Processing 490/827  (year=2013)\n",
      "Processing 500/827  (year=2013)\n",
      "[YEAR OUT] 2013 -> Dr_2013.nc, Dbedrock_2013.nc\n",
      "Processing 510/827  (year=2014)\n",
      "Processing 520/827  (year=2014)\n",
      "Processing 530/827  (year=2014)\n",
      "Processing 540/827  (year=2014)\n",
      "Processing 550/827  (year=2014)\n",
      "[YEAR OUT] 2014 -> Dr_2014.nc, Dbedrock_2014.nc\n",
      "Processing 560/827  (year=2015)\n",
      "Processing 570/827  (year=2015)\n",
      "Processing 580/827  (year=2015)\n",
      "Processing 590/827  (year=2015)\n",
      "[YEAR OUT] 2015 -> Dr_2015.nc, Dbedrock_2015.nc\n",
      "Processing 600/827  (year=2016)\n",
      "Processing 610/827  (year=2016)\n",
      "Processing 620/827  (year=2016)\n",
      "Processing 630/827  (year=2016)\n",
      "Processing 640/827  (year=2016)\n",
      "[YEAR OUT] 2016 -> Dr_2016.nc, Dbedrock_2016.nc\n",
      "Processing 650/827  (year=2017)\n",
      "Processing 660/827  (year=2017)\n",
      "Processing 670/827  (year=2017)\n",
      "Processing 680/827  (year=2017)\n",
      "[YEAR OUT] 2017 -> Dr_2017.nc, Dbedrock_2017.nc\n",
      "Processing 690/827  (year=2018)\n",
      "Processing 700/827  (year=2018)\n",
      "Processing 710/827  (year=2018)\n",
      "Processing 720/827  (year=2018)\n",
      "Processing 730/827  (year=2018)\n",
      "[YEAR OUT] 2018 -> Dr_2018.nc, Dbedrock_2018.nc\n",
      "Processing 740/827  (year=2019)\n",
      "Processing 750/827  (year=2019)\n",
      "Processing 760/827  (year=2019)\n",
      "Processing 770/827  (year=2019)\n",
      "Processing 780/827  (year=2019)\n",
      "[YEAR OUT] 2019 -> Dr_2019.nc, Dbedrock_2019.nc\n",
      "Processing 790/827  (year=2020)\n",
      "Processing 800/827  (year=2020)\n",
      "Processing 810/827  (year=2020)\n",
      "Processing 820/827  (year=2020)\n",
      "[YEAR OUT] 2020 -> Dr_2020.nc, Dbedrock_2020.nc\n",
      "[OK] Wrote CWD (year-reset): /tera04/zhwei/xionghui/bedrock/data/run/CWD_yearreset.nc\n",
      "[OK] Yearly Dr/Dbedrock in: /tera04/zhwei/xionghui/bedrock/data/run/reset_annual\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset, date2num\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ROOT_DIR = (NOTEBOOK_DIR / \"../data\").resolve()\n",
    "RUN_DIR  = ROOT_DIR / \"run\"\n",
    "OUT_DIR = RUN_DIR / \"reset_annual\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RES = \"p05\"\n",
    "\n",
    "ds  = xr.open_dataset(RUN_DIR / \"diff.nc\")\n",
    "ds2 = xr.open_dataset(ROOT_DIR / \"SC/SC.nc\")\n",
    "ds3 = xr.open_dataset(RUN_DIR / f\"Ssoil_{RES}.nc\")\n",
    "out_cwd = RUN_DIR / \"CWD_yearreset.nc\"\n",
    "\n",
    "diff  = ds[\"diff\"]    # (time, lat, lon) = (828, 3600, 7200)\n",
    "sc    = ds2[\"SC\"]     # (time, lat, lon)\n",
    "ssoil = ds3[\"Ssoil\"]  # (lat, lon)\n",
    "\n",
    "time_len = diff.sizes[\"time\"]\n",
    "nlat     = diff.sizes[\"lat\"]\n",
    "nlon     = diff.sizes[\"lon\"]\n",
    "\n",
    "# time decoding\n",
    "time_pd = pd.to_datetime(ds[\"time\"].values)\n",
    "years = time_pd.year.values\n",
    "uniq_years = np.unique(years)\n",
    "\n",
    "print(\"Time range:\", time_pd[0], \"to\", time_pd[-1], \"len=\", time_len)\n",
    "print(\"Years:\", uniq_years[0], \"->\", uniq_years[-1], \"N=\", len(uniq_years))\n",
    "print(\"Shape:\", (time_len, nlat, nlon))\n",
    "\n",
    "# =========================\n",
    "# 2D static arrays\n",
    "# =========================\n",
    "ssoil2d = ssoil.values.astype(np.float32)\n",
    "\n",
    "# =========================\n",
    "# OUTPUT: CWD (year-reset)\n",
    "# =========================\n",
    "\n",
    "\n",
    "# time encoding for netcdf\n",
    "time_dt   = time_pd.to_pydatetime()\n",
    "time_unit = \"days since 1970-01-01 00:00:00\"\n",
    "time_cal  = \"proleptic_gregorian\"\n",
    "time_num  = date2num(time_dt, units=time_unit, calendar=time_cal)\n",
    "\n",
    "# choose output chunk sizes (tune)\n",
    "chunk_t, chunk_y, chunk_x = 1, 600, 600\n",
    "chunk_y = min(chunk_y, nlat)\n",
    "chunk_x = min(chunk_x, nlon)\n",
    "\n",
    "# =========================\n",
    "# State arrays (reset per year)\n",
    "# =========================\n",
    "cwd_i = np.zeros((nlat, nlon), dtype=np.float32)  # running CWD within current year\n",
    "sr_y  = np.zeros((nlat, nlon), dtype=np.float32)  # max CWD within current year (Dr)\n",
    "\n",
    "def finalize_and_write_year(year, Dr2d, Ssoil2d):\n",
    "    \"\"\"\n",
    "    year: int\n",
    "    Dr2d: (lat, lon) float32, yearly max CWD\n",
    "    write:\n",
    "      Dr_{year}.nc\n",
    "      Dbedrock_{year}.nc\n",
    "    \"\"\"\n",
    "    Dbedrock2d = np.where(Dr2d > Ssoil2d, Dr2d - Ssoil2d, 0.0).astype(np.float32)\n",
    "\n",
    "    # 你要求：18个Dr_year.nc 和 18个Dbedrock_year.nc（每年各一个文件）\n",
    "    f_dr = OUT_DIR / f\"Dr_{year}.nc\"\n",
    "    f_db = OUT_DIR / f\"Dbedrock_{year}.nc\"\n",
    "\n",
    "    xr.Dataset(\n",
    "        {\"Dr\": ((\"lat\", \"lon\"), Dr2d)},\n",
    "        coords={\"lat\": ds[\"lat\"].values, \"lon\": ds[\"lon\"].values},\n",
    "    ).to_netcdf(f_dr)\n",
    "\n",
    "    xr.Dataset(\n",
    "        {\"Dbedrock\": ((\"lat\", \"lon\"), Dbedrock2d)},\n",
    "        coords={\"lat\": ds[\"lat\"].values, \"lon\": ds[\"lon\"].values},\n",
    "    ).to_netcdf(f_db)\n",
    "\n",
    "    print(f\"[YEAR OUT] {year} -> {f_dr.name}, {f_db.name}\")\n",
    "\n",
    "# =========================\n",
    "# STREAM WRITE CWD_yearreset.nc\n",
    "# =========================\n",
    "with Dataset(out_cwd, \"w\", format=\"NETCDF4\") as nc:\n",
    "    nc.createDimension(\"time\", time_len)\n",
    "    nc.createDimension(\"lat\",  nlat)\n",
    "    nc.createDimension(\"lon\",  nlon)\n",
    "\n",
    "    vtime = nc.createVariable(\"time\", \"f8\", (\"time\",))\n",
    "    vtime.units = time_unit\n",
    "    vtime.calendar = time_cal\n",
    "    vtime[:] = time_num\n",
    "\n",
    "    vlon = nc.createVariable(\"lon\", \"f4\", (\"lon\",))\n",
    "    vlon.units = \"degrees_east\"\n",
    "    vlon[:] = ds[\"lon\"].values.astype(np.float32)\n",
    "\n",
    "    vlat = nc.createVariable(\"lat\", \"f4\", (\"lat\",))\n",
    "    vlat.units = \"degrees_north\"\n",
    "    vlat[:] = ds[\"lat\"].values.astype(np.float32)\n",
    "\n",
    "    vCWD = nc.createVariable(\n",
    "        \"CWD\", \"f4\", (\"time\", \"lat\", \"lon\"),\n",
    "        zlib=True, complevel=3, shuffle=True,\n",
    "        chunksizes=(chunk_t, chunk_y, chunk_x),\n",
    "        fill_value=np.float32(np.nan)\n",
    "    )\n",
    "    vCWD.long_name = \"Cumulative Water Deficit (8-day running state, reset to 0 at each year boundary)\"\n",
    "\n",
    "    # 初始化当前年份\n",
    "    curr_year = int(years[0])\n",
    "\n",
    "    # 逐时次处理\n",
    "    for i in range(time_len):\n",
    "        y = int(years[i])\n",
    "\n",
    "        # 进入新的一年：先把上一年的 Dr/Dbedrock 写出去，然后重置状态\n",
    "        if y != curr_year:\n",
    "            # finalize previous year\n",
    "            finalize_and_write_year(curr_year, sr_y, ssoil2d)\n",
    "\n",
    "            # reset for new year\n",
    "            cwd_i.fill(0.0)\n",
    "            sr_y.fill(0.0)\n",
    "            curr_year = y\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing {i}/{time_len-1}  (year={y})\")\n",
    "\n",
    "        # 读当前时次\n",
    "        diff_i = diff.isel(time=i).values.astype(np.float32)\n",
    "        sc_i   = sc.isel(time=i).values.astype(np.float32)\n",
    "\n",
    "        # 年内累计（与你原逻辑一致，只是跨年重置了 cwd_i）\n",
    "        delta_tn_i = diff_i * sc_i\n",
    "        cwd_i = np.where(delta_tn_i >= 0, cwd_i + delta_tn_i, 0.0).astype(np.float32)\n",
    "\n",
    "        # 当年最大值 Dr（年内最大 CWD）\n",
    "        sr_y = np.maximum(sr_y, cwd_i)\n",
    "\n",
    "        # 写出该时次的 CWD（全时段 828 都会写）\n",
    "        vCWD[i, :, :] = cwd_i\n",
    "\n",
    "    # 循环结束后：别忘了输出最后一年\n",
    "    finalize_and_write_year(curr_year, sr_y, ssoil2d)\n",
    "\n",
    "print(\"[OK] Wrote CWD (year-reset):\", out_cwd)\n",
    "print(\"[OK] Yearly Dr/Dbedrock in:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
