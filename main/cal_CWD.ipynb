{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b748a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_916448/292607578.py:10: UserWarning: The specified chunks separate the stored chunks along dimension \"lon\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds  = xr.open_dataset(f'{data_path}diff/diff.nc', chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/292607578.py:11: UserWarning: The specified chunks separate the stored chunks along dimension \"lat\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds2 = xr.open_dataset(f'{data_path}SC/SC.nc', chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/292607578.py:11: UserWarning: The specified chunks separate the stored chunks along dimension \"lon\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds2 = xr.open_dataset(f'{data_path}SC/SC.nc', chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/292607578.py:12: UserWarning: The specified chunks separate the stored chunks along dimension \"lat\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds3 = xr.open_dataset(f'{data_path}Ssoil/Ssoil.nc', chunks={\"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/292607578.py:12: UserWarning: The specified chunks separate the stored chunks along dimension \"lon\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds3 = xr.open_dataset(f'{data_path}Ssoil/Ssoil.nc', chunks={\"lat\": 200, \"lon\": 200})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex or align along dimension 'time' because the (pandas) index has duplicate values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m sc = ds2[\u001b[33m\"\u001b[39m\u001b[33mSC\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m ssoil = ds3[\u001b[33m\"\u001b[39m\u001b[33mSsoil\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m x = (\u001b[43mdiff\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m).transpose(\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlon\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# 保证 time 在第一维，利于 scan\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 2) 用 numba 写一个沿 time 的递推\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#    输入: (time, y, x) -> 输出: sr(y,x)\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;129m@nb\u001b[39m.njit(parallel=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msr_from_x\u001b[39m(x3d):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/core/_typed_ops.py:552\u001b[39m, in \u001b[36mDataArrayOpsMixin.__mul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: DaCompatible) -> Self | Dataset | DataTree:\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/core/dataarray.py:4840\u001b[39m, in \u001b[36mDataArray._binary_op\u001b[39m\u001b[34m(self, other, f, reflexive)\u001b[39m\n\u001b[32m   4838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, DataArray):\n\u001b[32m   4839\u001b[39m     align_type = OPTIONS[\u001b[33m\"\u001b[39m\u001b[33marithmetic_join\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m4840\u001b[39m     \u001b[38;5;28mself\u001b[39m, other = \u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4841\u001b[39m other_variable_or_arraylike: DaCompatible = \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[33m\"\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m\"\u001b[39m, other)\n\u001b[32m   4842\u001b[39m other_coords = \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[33m\"\u001b[39m\u001b[33mcoords\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/structure/alignment.py:944\u001b[39m, in \u001b[36malign\u001b[39m\u001b[34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    749\u001b[39m \u001b[33;03mGiven any number of Dataset and/or DataArray objects, returns new\u001b[39;00m\n\u001b[32m    750\u001b[39m \u001b[33;03mobjects with aligned indexes and dimension sizes.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    934\u001b[39m \n\u001b[32m    935\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    936\u001b[39m aligner = Aligner(\n\u001b[32m    937\u001b[39m     objects,\n\u001b[32m    938\u001b[39m     join=join,\n\u001b[32m   (...)\u001b[39m\u001b[32m    942\u001b[39m     fill_value=fill_value,\n\u001b[32m    943\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m \u001b[43maligner\u001b[49m\u001b[43m.\u001b[49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m aligner.results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/structure/alignment.py:644\u001b[39m, in \u001b[36mAligner.align\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    642\u001b[39m     \u001b[38;5;28mself\u001b[39m.results = \u001b[38;5;28mself\u001b[39m.objects\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/structure/alignment.py:615\u001b[39m, in \u001b[36mAligner.reindex_all\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreindex_all\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     \u001b[38;5;28mself\u001b[39m.results = \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects_matching_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects_matching_index_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/structure/alignment.py:602\u001b[39m, in \u001b[36mAligner._reindex_one\u001b[39m\u001b[34m(self, obj, matching_indexes, matching_index_vars)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reindex_one\u001b[39m(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    595\u001b[39m     obj: T_Alignable,\n\u001b[32m    596\u001b[39m     matching_indexes: \u001b[38;5;28mdict\u001b[39m[MatchingIndexKey, Index],\n\u001b[32m    597\u001b[39m     matching_index_vars: \u001b[38;5;28mdict\u001b[39m[MatchingIndexKey, \u001b[38;5;28mdict\u001b[39m[Hashable, Variable]],\n\u001b[32m    598\u001b[39m ) -> T_Alignable:\n\u001b[32m    599\u001b[39m     new_indexes, new_variables = \u001b[38;5;28mself\u001b[39m._get_indexes_and_vars(\n\u001b[32m    600\u001b[39m         obj, matching_indexes, matching_index_vars\n\u001b[32m    601\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m     dim_pos_indexers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_dim_pos_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatching_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._reindex_callback(\n\u001b[32m    605\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    606\u001b[39m         dim_pos_indexers,\n\u001b[32m   (...)\u001b[39m\u001b[32m    611\u001b[39m         \u001b[38;5;28mself\u001b[39m.exclude_vars,\n\u001b[32m    612\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/structure/alignment.py:533\u001b[39m, in \u001b[36mAligner._get_dim_pos_indexers\u001b[39m\u001b[34m(self, matching_indexes)\u001b[39m\n\u001b[32m    531\u001b[39m obj_idx = matching_indexes.get(key)\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reindex[key]:\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     indexers = \u001b[43mobj_idx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43maligned_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m dim, idxer \u001b[38;5;129;01min\u001b[39;00m indexers.items():\n\u001b[32m    535\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exclude_dims:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/core/indexes.py:906\u001b[39m, in \u001b[36mPandasIndex.reindex_like\u001b[39m\u001b[34m(self, other, method, tolerance)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreindex_like\u001b[39m(\n\u001b[32m    903\u001b[39m     \u001b[38;5;28mself\u001b[39m, other: Self, method=\u001b[38;5;28;01mNone\u001b[39;00m, tolerance=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    904\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[Hashable, Any]:\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.index.is_unique:\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    907\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot reindex or align along dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.dim\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m because the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    908\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m(pandas) index has duplicate values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m.dim: get_indexer_nd(\u001b[38;5;28mself\u001b[39m.index, other.index, method, tolerance)}\n",
      "\u001b[31mValueError\u001b[39m: cannot reindex or align along dimension 'time' because the (pandas) index has duplicate values"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "\n",
    "# ---------------------------\n",
    "# 1) 以 chunk 方式懒加载（不要 .values）\n",
    "# ---------------------------\n",
    "data_path = f'/share/home/dq076/bedrock/data/'\n",
    "\n",
    "ds  = xr.open_dataset(f'{data_path}diff/diff.nc', chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
    "ds2 = xr.open_dataset(f'{data_path}SC/SC.nc', chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
    "ds3 = xr.open_dataset(f'{data_path}Ssoil/Ssoil.nc', chunks={\"lat\": 200, \"lon\": 200})\n",
    "\n",
    "# 变量（按你说的：diff.nc 是 ET-P；sc 已是0/1权重；ssoil是2D）\n",
    "diff  = ds[\"diff\"].astype(\"float32\")\n",
    "sc = ds2[\"SC\"].astype(\"float32\")\n",
    "ssoil = ds3[\"Ssoil\"].astype(\"float32\")\n",
    "\n",
    "x = (diff * sc).transpose(\"time\", \"lat\", \"lon\")  # 保证 time 在第一维，利于 scan\n",
    "\n",
    "# ---------------------------\n",
    "# 2) 用 numba 写一个沿 time 的递推\n",
    "#    输入: (time, y, x) -> 输出: sr(y,x)\n",
    "# ---------------------------\n",
    "@nb.njit(parallel=True)\n",
    "def sr_from_x(x3d):\n",
    "    T, Y, X = x3d.shape\n",
    "    sr = np.zeros((Y, X), dtype=x3d.dtype)\n",
    "    cwd = np.zeros((Y, X), dtype=x3d.dtype)\n",
    "\n",
    "    for t in range(T):\n",
    "        xt = x3d[t]\n",
    "        # 逐像元更新\n",
    "        for j in nb.prange(Y):\n",
    "            for i in range(X):\n",
    "                v = xt[j, i]\n",
    "                if v >= 0:\n",
    "                    cwd[j, i] = cwd[j, i] + v\n",
    "                else:\n",
    "                    cwd[j, i] = 0.0\n",
    "                if cwd[j, i] > sr[j, i]:\n",
    "                    sr[j, i] = cwd[j, i]\n",
    "    return sr\n",
    "\n",
    "# ---------------------------\n",
    "# 3) apply_ufunc：让 numba 函数在每个 dask block 上跑\n",
    "# ---------------------------\n",
    "sr = xr.apply_ufunc(\n",
    "    sr_from_x,\n",
    "    x,\n",
    "    input_core_dims=[[\"time\", \"lat\", \"lon\"]],\n",
    "    output_core_dims=[[\"lat\", \"lon\"]],\n",
    "    dask=\"parallelized\",\n",
    "    vectorize=False,\n",
    "    output_dtypes=[\"float32\"],\n",
    ")\n",
    "\n",
    "# sbedrock\n",
    "sbedrock = xr.where(sr > ssoil, sr - ssoil, 0.0).astype(\"float32\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) 输出（压缩 + 合理 chunk）\n",
    "# ---------------------------\n",
    "encoding_2d = {\n",
    "    \"zlib\": True, \"complevel\": 4, \"dtype\": \"float32\",\n",
    "    \"chunksizes\": (200, 200),\n",
    "}\n",
    "\n",
    "xr.Dataset({\"Sr\": sr}).to_netcdf(\n",
    "    f\"{data_path}Sr.nc\",\n",
    "    encoding={\"Sr\": encoding_2d}\n",
    ")\n",
    "\n",
    "xr.Dataset({\"Sbedrock\": sbedrock}).to_netcdf(\n",
    "    f\"{data_path}Sbedrock.nc\",\n",
    "    encoding={\"Sbedrock\": encoding_2d}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556134e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n",
      "diff duplicates: DatetimeIndex([], dtype='datetime64[ns]', name='time', freq=None)\n",
      "SC   duplicates: DatetimeIndex(['2003-12-29 00:00:00', '2004-12-28 12:00:00',\n",
      "               '2005-12-29 00:00:00', '2006-12-29 00:00:00',\n",
      "               '2007-12-29 00:00:00', '2008-12-28 12:00:00',\n",
      "               '2009-12-29 00:00:00', '2010-12-29 00:00:00',\n",
      "               '2011-12-29 00:00:00', '2012-12-28 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"time\"].to_index().has_duplicates, ds2[\"time\"].to_index().has_duplicates)\n",
    "# 或者更直观\n",
    "t1 = ds[\"time\"].to_index()\n",
    "t2 = ds2[\"time\"].to_index()\n",
    "print(\"diff duplicates:\", t1[t1.duplicated()].unique()[:10])\n",
    "print(\"SC   duplicates:\", t2[t2.duplicated()].unique()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cec8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_916448/1736772171.py:7: UserWarning: The specified chunks separate the stored chunks along dimension \"lon\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds  = xr.open_dataset(f\"{data_path}diff/diff.nc\", chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/1736772171.py:8: UserWarning: The specified chunks separate the stored chunks along dimension \"lat\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds2 = xr.open_dataset(f\"{data_path}SC/SC.nc\",     chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/1736772171.py:8: UserWarning: The specified chunks separate the stored chunks along dimension \"lon\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds2 = xr.open_dataset(f\"{data_path}SC/SC.nc\",     chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/1736772171.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"lat\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds3 = xr.open_dataset(f\"{data_path}Ssoil/Ssoil.nc\", chunks={\"lat\": 200, \"lon\": 200})\n",
      "/tmp/ipykernel_916448/1736772171.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"lon\" starting at index 200. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  ds3 = xr.open_dataset(f\"{data_path}Ssoil/Ssoil.nc\", chunks={\"lat\": 200, \"lon\": 200})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m sbedrock = xr.where(sr > ssoil, sr - ssoil, \u001b[32m0.0\u001b[39m).astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m).rename(\u001b[33m\"\u001b[39m\u001b[33mSbedrock\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     58\u001b[39m encoding_2d = {\u001b[33m\"\u001b[39m\u001b[33mzlib\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcomplevel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mchunksizes\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[32m200\u001b[39m, \u001b[32m200\u001b[39m)}\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mSr.nc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnetcdf4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNETCDF4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding_2d\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m xr.Dataset({\u001b[33m\"\u001b[39m\u001b[33mSbedrock\u001b[39m\u001b[33m\"\u001b[39m: sbedrock}).to_netcdf(\n\u001b[32m     67\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mSbedrock.nc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m     engine=\u001b[33m\"\u001b[39m\u001b[33mnetcdf4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mNETCDF4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m     encoding={\u001b[33m\"\u001b[39m\u001b[33mSbedrock\u001b[39m\u001b[33m\"\u001b[39m: encoding_2d},\n\u001b[32m     70\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/core/dataset.py:2029\u001b[39m, in \u001b[36mDataset.to_netcdf\u001b[39m\u001b[34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[39m\n\u001b[32m   2026\u001b[39m     encoding = {}\n\u001b[32m   2027\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxarray\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[32m-> \u001b[39m\u001b[32m2029\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[32m   2030\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2033\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2034\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2036\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2037\u001b[39m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2038\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2039\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2040\u001b[39m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2042\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/backends/api.py:1993\u001b[39m, in \u001b[36mto_netcdf\u001b[39m\u001b[34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multifile:\n\u001b[32m   1991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m writer, store\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m writes = \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, BytesIO):\n\u001b[32m   1996\u001b[39m     store.sync()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/backends/common.py:357\u001b[39m, in \u001b[36mArrayWriter.sync\u001b[39m\u001b[34m(self, compute, chunkmanager_store_kwargs)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunkmanager_store_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    355\u001b[39m     chunkmanager_store_kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m delayed_store = \u001b[43mchunkmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflush\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mchunkmanager_store_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m.sources = []\n\u001b[32m    367\u001b[39m \u001b[38;5;28mself\u001b[39m.targets = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/xarray/namedarray/daskmanager.py:247\u001b[39m, in \u001b[36mDaskManager.store\u001b[39m\u001b[34m(self, sources, targets, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore\u001b[39m(\n\u001b[32m    240\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    241\u001b[39m     sources: Any | Sequence[Any],\n\u001b[32m    242\u001b[39m     targets: Any,\n\u001b[32m    243\u001b[39m     **kwargs: Any,\n\u001b[32m    244\u001b[39m ) -> Any:\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdask\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m store\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43msources\u001b[49m\u001b[43m=\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/dask/array/core.py:1218\u001b[39m, in \u001b[36mstore\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_stored:\n\u001b[32m   1216\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdask\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m     \u001b[43mdask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/site-packages/dask/base.py:686\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m     expr = expr.optimize()\n\u001b[32m    684\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/queue.py:202\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    204\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software/miniconda3/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "\n",
    "data_path = \"/share/home/dq076/bedrock/data/\"\n",
    "\n",
    "ds  = xr.open_dataset(f\"{data_path}diff/diff.nc\", chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
    "ds2 = xr.open_dataset(f\"{data_path}SC/SC.nc\",     chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
    "ds3 = xr.open_dataset(f\"{data_path}Ssoil/Ssoil.nc\", chunks={\"lat\": 200, \"lon\": 200})\n",
    "\n",
    "diff  = ds[\"diff\"].astype(\"float32\").transpose(\"time\", \"lat\", \"lon\")\n",
    "sc    = ds2[\"SC\"].astype(\"float32\").transpose(\"time\", \"lat\", \"lon\")\n",
    "ssoil = ds3[\"Ssoil\"].astype(\"float32\").transpose(\"lat\", \"lon\")\n",
    "\n",
    "# 按位置相乘（避免 time 重复导致 align）\n",
    "x = xr.DataArray(\n",
    "    diff.data * sc.data,\n",
    "    dims=(\"time\", \"lat\", \"lon\"),\n",
    "    coords={\"time\": diff[\"time\"], \"lat\": diff[\"lat\"], \"lon\": diff[\"lon\"]},\n",
    "    name=\"x\",\n",
    ")\n",
    "\n",
    "# 关键：写一个只沿最后一个维度 time 扫描的函数\n",
    "# xarray 会把 time 放到 core dim 上，其它维度（lat,lon chunk）作为“批量维度”喂进来\n",
    "@nb.njit\n",
    "def sr_from_x_1d(x1d):\n",
    "    \"\"\"x1d: (T,) -> sr scalar\"\"\"\n",
    "    sr = np.float32(0.0)\n",
    "    cwd = np.float32(0.0)\n",
    "    for t in range(x1d.shape[0]):\n",
    "        v = x1d[t]\n",
    "        if v >= 0:\n",
    "            cwd = cwd + v\n",
    "        else:\n",
    "            cwd = 0.0\n",
    "        if cwd > sr:\n",
    "            sr = cwd\n",
    "    return sr\n",
    "\n",
    "# 将 sr_from_x_1d 向量化到 (lat,lon) 上：输出是 (lat,lon)\n",
    "sr = xr.apply_ufunc(\n",
    "    sr_from_x_1d,\n",
    "    x,\n",
    "    input_core_dims=[[\"time\"]],     # ✅ 只有 time 是 core dim\n",
    "    output_core_dims=[[]],          # ✅ 输出是标量（对每个像元）\n",
    "    vectorize=True,                 # ✅ 对 lat/lon 自动向量化\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[\"float32\"],\n",
    "    dask_gufunc_kwargs={\"allow_rechunk\": False},  # 不需要重分块\n",
    ")\n",
    "\n",
    "# 恢复成 (lat,lon) 的 DataArray\n",
    "sr = sr.rename(\"Sr\")\n",
    "\n",
    "# sbedrock\n",
    "sbedrock = xr.where(sr > ssoil, sr - ssoil, 0.0).astype(\"float32\").rename(\"Sbedrock\")\n",
    "\n",
    "encoding_2d = {\"zlib\": True, \"complevel\": 4, \"dtype\": \"float32\", \"chunksizes\": (200, 200)}\n",
    "\n",
    "xr.Dataset({\"Sr\": sr}).to_netcdf(\n",
    "    f\"{data_path}Sr.nc\",\n",
    "    engine=\"netcdf4\", format=\"NETCDF4\",\n",
    "    encoding={\"Sr\": encoding_2d},\n",
    ")\n",
    "\n",
    "xr.Dataset({\"Sbedrock\": sbedrock}).to_netcdf(\n",
    "    f\"{data_path}Sbedrock.nc\",\n",
    "    engine=\"netcdf4\", format=\"NETCDF4\",\n",
    "    encoding={\"Sbedrock\": encoding_2d},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62136ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "\n",
    "data_path = f'/share/home/dq076/bedrock/data/'\n",
    "\n",
    "ds  = xr.open_dataset(f'{data_path}diff/diff.nc', chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
    "ds2 = xr.open_dataset(f'{data_path}SC/sc.nc', chunks={\"time\": -1, \"lat\": 200, \"lon\": 200})\n",
    "\n",
    "diff  = ds[\"diff\"].astype(\"float32\")       # 这里假设变量名是 et = ET-P\n",
    "sc = ds2[\"sc\"].astype(\"float32\")   # 0/1 mask\n",
    "\n",
    "# 递推输入：x_t\n",
    "x = (diff * sc).transpose(\"time\", \"lat\", \"lon\")  # time放前面更快\n",
    "\n",
    "# 2) numba：输出整个 time 序列的 cwd (T,Y,X)\n",
    "@nb.njit(parallel=True)\n",
    "def cwd_series_from_x(x3d):\n",
    "    T, Y, X = x3d.shape\n",
    "    out = np.empty((T, Y, X), dtype=x3d.dtype)\n",
    "\n",
    "    cwd = np.zeros((Y, X), dtype=x3d.dtype)\n",
    "    for t in range(T):\n",
    "        xt = x3d[t]\n",
    "        for j in nb.prange(Y):\n",
    "            for i in range(X):\n",
    "                v = xt[j, i]\n",
    "                if v >= 0:\n",
    "                    cwd[j, i] = cwd[j, i] + v\n",
    "                else:\n",
    "                    cwd[j, i] = 0.0\n",
    "                out[t, j, i] = cwd[j, i]\n",
    "    return out\n",
    "\n",
    "# 3) apply_ufunc：让上面的 numba 在每个 dask block 上跑\n",
    "cwd = xr.apply_ufunc(\n",
    "    cwd_series_from_x,\n",
    "    x,\n",
    "    input_core_dims=[[\"time\", \"lat\", \"lon\"]],\n",
    "    output_core_dims=[[\"time\", \"lat\", \"lon\"]],\n",
    "    dask=\"parallelized\",\n",
    "    vectorize=False,\n",
    "    output_dtypes=[\"float32\"],\n",
    ")\n",
    "\n",
    "# 恢复原坐标（time/lat/lon）\n",
    "cwd = cwd.assign_coords(time=ds[\"time\"], lat=ds[\"lat\"], lon=ds[\"lon\"])\n",
    "cwd.name = \"CWD\"\n",
    "cwd.attrs.update({\"long_name\": \"Cumulative Water Deficit\", \"units\": \"mm\"})\n",
    "\n",
    "# 4) 写出：强烈建议 chunk + 压缩，否则很慢很大\n",
    "# time 维 chunk 一般设 1~10 比较好（方便按时刻访问），lat/lon 按块一致\n",
    "encoding = {\n",
    "    \"CWD\": {\n",
    "        \"zlib\": True,\n",
    "        \"complevel\": 4,\n",
    "        \"dtype\": \"float32\",\n",
    "        \"chunksizes\": (1, 200, 200),   # (time,lat,lon)\n",
    "        \"_FillValue\": np.float32(0.0),\n",
    "    }\n",
    "}\n",
    "\n",
    "xr.Dataset({\"CWD\": cwd}).to_netcdf(f\"{data_path}CWD/CWD.nc\", encoding=encoding)\n",
    "print(\"CWD.nc has storage\")\n",
    "xr.Dataset({\"CWD\": cwd}).to_zarr(f\"{data_path}CWD/CWD.zarr\", mode=\"w\")\n",
    "print(\"CWD.zarr has storage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
