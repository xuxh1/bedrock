{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865798ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FALSE'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# ==========\n",
    "# 线程超卖控制（重要）\n",
    "# ==========\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "# 如果你的文件系统锁会出问题，可尝试：\n",
    "os.environ.setdefault(\"HDF5_USE_PATH_LOCKING\", \"FALSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95229431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# PATH CONFIG\n",
    "# ======================\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "ROOT_DIR = (NOTEBOOK_DIR / \"../data\").resolve()\n",
    "RUN_DIR = ROOT_DIR / \"run\"\n",
    "CWD_PATH  = RUN_DIR / \"CWD.nc\"\n",
    "dEF_PATH  = ROOT_DIR / \"ET/dEF.nc\"\n",
    "dSIF_PATH = ROOT_DIR / \"SIF/dSIF.nc\"\n",
    "\n",
    "OUT_GLOBAL_DIR = RUN_DIR / \"veg_activity\"\n",
    "OUT_GLOBAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_TILE_DIR = RUN_DIR / \"veg_activity/tiles\"\n",
    "OUT_TILE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ======================\n",
    "# VARIABLE NAMES\n",
    "# ======================\n",
    "VAR_CWD  = \"CWD\"\n",
    "VAR_dEF  = \"dEF\"\n",
    "VAR_dSIF = \"dSIF\"\n",
    "\n",
    "# ======================\n",
    "# TILE CONFIG\n",
    "# ======================\n",
    "TILE_Y = 300   # lat block\n",
    "TILE_X = 300   # lon block\n",
    "\n",
    "# ======================\n",
    "# METHOD PARAMS\n",
    "# ======================\n",
    "NBINS = 50\n",
    "Q = 0.90\n",
    "\n",
    "MIN_EVENT_STEPS = 1       # >=8天; 你的数据是8-day，所以1 step = 8天\n",
    "MINVALIDBINS = 8\n",
    "MINPOINTSTOTAL = 30\n",
    "\n",
    "RUNAWAY_YEARS = 5         # 连续>=5年无CWD<=0重置 -> discard pixel\n",
    "\n",
    "# 缺测值处理（你的 dEF/dSIF 是 -9999）\n",
    "FILL_X = -9999.0\n",
    "\n",
    "# 输出压缩\n",
    "ENC_2D = dict(zlib=True, complevel=4, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b0f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 828, lat: 3600, lon: 7200)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2003-01-01 2003-01-09 ... 2020-12-26\n",
      "  * lat      (lat) float32 -89.97 -89.93 -89.88 -89.82 ... 89.88 89.93 89.97\n",
      "  * lon      (lon) float32 -180.0 -179.9 -179.9 -179.8 ... 179.9 179.9 180.0\n",
      "Data variables:\n",
      "    CWD      (time, lat, lon) float32 ...\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 828, lon: 7200, lat: 3600)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2003-01-01 2003-01-09 ... 2020-12-26\n",
      "  * lon      (lon) float64 -180.0 -179.9 -179.9 -179.8 ... 179.9 179.9 180.0\n",
      "  * lat      (lat) float64 -89.97 -89.92 -89.88 -89.83 ... 89.88 89.93 89.98\n",
      "Data variables:\n",
      "    crs      |S1 ...\n",
      "    dEF      (time, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    CDI:                 Climate Data Interface version 2.5.0 (https://mpimet...\n",
      "    Conventions:         CF-1.5\n",
      "    GDAL_AREA_OR_POINT:  Area\n",
      "    GDAL:                GDAL 3.10.3, released 2025/04/01\n",
      "    history:             Fri Jan 09 21:33:58 2026: cdo -O -L -b F32 -f nc4 -z...\n",
      "    CDO:                 Climate Data Operators version 2.5.0 (https://mpimet...\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 828, lon: 7200, lat: 3600)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2003-01-01 2003-01-09 ... 2020-12-26\n",
      "  * lon      (lon) float64 -180.0 -179.9 -179.9 -179.8 ... 179.9 179.9 180.0\n",
      "  * lat      (lat) float64 -89.97 -89.92 -89.88 -89.83 ... 89.88 89.93 89.98\n",
      "Data variables:\n",
      "    crs      |S1 ...\n",
      "    dSIF     (time, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    CDI:                    Climate Data Interface version 2.5.0 (https://mpi...\n",
      "    Conventions:            CF-1.5\n",
      "    GDAL_AREA_OR_POINT:     Area\n",
      "    GDAL_TIFFTAG_SOFTWARE:  MATLAB 8.6, Mapping Toolbox 4.2\n",
      "    GDAL:                   GDAL 3.10.3, released 2025/04/01\n",
      "    history:                Fri Jan 09 21:35:29 2026: cdo -O -L -b F32 -f nc4...\n",
      "    CDO:                    Climate Data Operators version 2.5.0 (https://mpi...\n",
      "time: 2003-01-01T00:00:00.000000000 -> 2020-12-26T00:00:00.000000000 len= 828\n",
      "lat: -89.975 89.975 n= 3600\n",
      "lon: -179.975 179.975 n= 7200\n"
     ]
    }
   ],
   "source": [
    "ds_cwd  = xr.open_dataset(CWD_PATH,  engine=\"netcdf4\")\n",
    "ds_def  = xr.open_dataset(dEF_PATH,  engine=\"netcdf4\")\n",
    "ds_dsif = xr.open_dataset(dSIF_PATH, engine=\"netcdf4\")\n",
    "\n",
    "print(ds_cwd)\n",
    "print(ds_def)\n",
    "print(ds_dsif)\n",
    "\n",
    "# 取 time/lat/lon，确保一致\n",
    "time = ds_cwd[\"time\"].values\n",
    "lat  = ds_cwd[\"lat\"].values\n",
    "lon  = ds_cwd[\"lon\"].values\n",
    "\n",
    "assert ds_def[\"time\"].size == ds_cwd[\"time\"].size\n",
    "assert ds_dsif[\"time\"].size == ds_cwd[\"time\"].size\n",
    "assert ds_def[\"lat\"].size  == ds_cwd[\"lat\"].size\n",
    "assert ds_def[\"lon\"].size  == ds_cwd[\"lon\"].size\n",
    "\n",
    "print(\"time:\", time[0], \"->\", time[-1], \"len=\", len(time))\n",
    "print(\"lat:\", lat[0], lat[-1], \"n=\", len(lat))\n",
    "print(\"lon:\", lon[0], lon[-1], \"n=\", len(lon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdddb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N years: 18 first/last: [ 0 46] [782 828]\n"
     ]
    }
   ],
   "source": [
    "def build_year_slices(time_index: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    return int32 array shape (n_years, 2) with [start, end) indices\n",
    "    \"\"\"\n",
    "    t = pd.to_datetime(time_index)\n",
    "    years = t.year.values\n",
    "    uniq_years = np.unique(years)\n",
    "    slices = []\n",
    "    for y in uniq_years:\n",
    "        idx = np.where(years == y)[0]\n",
    "        if idx.size == 0:\n",
    "            continue\n",
    "        slices.append((int(idx[0]), int(idx[-1] + 1)))\n",
    "    return np.array(slices, dtype=np.int32)\n",
    "\n",
    "YEAR_SLICES = build_year_slices(time)\n",
    "print(\"N years:\", YEAR_SLICES.shape[0], \"first/last:\", YEAR_SLICES[0], YEAR_SLICES[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20af3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tiles: 288\n",
      "Example tile: (0, 300, 0, 300)\n"
     ]
    }
   ],
   "source": [
    "NY = len(lat)\n",
    "NX = len(lon)\n",
    "\n",
    "def make_tiles(ny, nx, tile_y, tile_x):\n",
    "    tiles = []\n",
    "    for y0 in range(0, ny, tile_y):\n",
    "        y1 = min(ny, y0 + tile_y)\n",
    "        for x0 in range(0, nx, tile_x):\n",
    "            x1 = min(nx, x0 + tile_x)\n",
    "            tiles.append((y0, y1, x0, x1))\n",
    "    return tiles\n",
    "\n",
    "TILES = make_tiles(NY, NX, TILE_Y, TILE_X)\n",
    "print(\"Total tiles:\", len(TILES))\n",
    "print(\"Example tile:\", TILES[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656fc5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828, 300, 300) (828, 300, 300) (828, 300, 300)\n",
      "CWD finite ratio: 1.0\n",
      "dEF finite ratio: 0.0\n",
      "dSIF finite ratio: 3.6500268384326356e-06\n"
     ]
    }
   ],
   "source": [
    "def load_tile(y0, y1, x0, x1):\n",
    "    cwd  = ds_cwd[VAR_CWD].isel(lat=slice(y0,y1), lon=slice(x0,x1)).transpose(\"time\",\"lat\",\"lon\").load()\n",
    "    dEF  = ds_def[VAR_dEF].isel(lat=slice(y0,y1), lon=slice(x0,x1)).transpose(\"time\",\"lat\",\"lon\").load()\n",
    "    dSIF = ds_dsif[VAR_dSIF].isel(lat=slice(y0,y1), lon=slice(x0,x1)).transpose(\"time\",\"lat\",\"lon\").load()\n",
    "\n",
    "    # 缺测：-9999 -> NaN\n",
    "    dEF  = dEF.where(dEF != FILL_X)\n",
    "    dSIF = dSIF.where(dSIF != FILL_X)\n",
    "\n",
    "    # 转 float32（减内存/加速）\n",
    "    return (cwd.data.astype(np.float32),\n",
    "            dEF.data.astype(np.float32),\n",
    "            dSIF.data.astype(np.float32))\n",
    "\n",
    "# 试一个 tile\n",
    "y0,y1,x0,x1 = TILES[0]\n",
    "cwd_t, def_t, dsif_t = load_tile(y0,y1,x0,x1)\n",
    "print(cwd_t.shape, def_t.shape, dsif_t.shape)\n",
    "print(\"CWD finite ratio:\", np.isfinite(cwd_t).mean())\n",
    "print(\"dEF finite ratio:\", np.isfinite(def_t).mean())\n",
    "print(\"dSIF finite ratio:\", np.isfinite(dsif_t).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55d32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.njit(cache=True)\n",
    "def _event_window_one_year(cwd_year, min_event_steps):\n",
    "    \"\"\"\n",
    "    cwd_year: 1D float32, length Ty\n",
    "    return (ok, start, end_exclusive, cwdmax)\n",
    "    \"\"\"\n",
    "    Ty = cwd_year.size\n",
    "    # 找 peak（最大值）\n",
    "    peak = -1\n",
    "    cwdmax = -1e30\n",
    "    for i in range(Ty):\n",
    "        v = cwd_year[i]\n",
    "        if np.isfinite(v) and v > cwdmax:\n",
    "            cwdmax = v\n",
    "            peak = i\n",
    "    if peak < 0 or not np.isfinite(cwdmax) or cwdmax <= 0.0:\n",
    "        return 0, 0, 0, 0.0\n",
    "\n",
    "    # start: 从 peak 向前找最后一个 CWD<=0\n",
    "    start = 0\n",
    "    for i in range(peak, -1, -1):\n",
    "        v = cwd_year[i]\n",
    "        if np.isfinite(v) and v <= 0.0:\n",
    "            start = i\n",
    "            break\n",
    "\n",
    "    # end: 从 peak 向后找第一个 CWD < 0.9*CWDmax\n",
    "    thr = 0.9 * cwdmax\n",
    "    end = Ty\n",
    "    for i in range(peak, Ty):\n",
    "        v = cwd_year[i]\n",
    "        if np.isfinite(v) and v < thr:\n",
    "            end = i\n",
    "            break\n",
    "\n",
    "    if end - start < min_event_steps:\n",
    "        return 0, 0, 0, 0.0\n",
    "\n",
    "    return 1, start, end, cwdmax\n",
    "\n",
    "\n",
    "@nb.njit(cache=True)\n",
    "def _count_runaway_years(cwd, year_slices):\n",
    "    \"\"\"\n",
    "    统计“连续多少年该年内从未出现 CWD<=0”（即没有重置）。\n",
    "    返回 max consecutive years.\n",
    "    \"\"\"\n",
    "    nY = year_slices.shape[0]\n",
    "    max_consec = 0\n",
    "    consec = 0\n",
    "    for yi in range(nY):\n",
    "        s = year_slices[yi,0]\n",
    "        e = year_slices[yi,1]\n",
    "        has_reset = False\n",
    "        for t in range(s, e):\n",
    "            v = cwd[t]\n",
    "            if np.isfinite(v) and v <= 0.0:\n",
    "                has_reset = True\n",
    "                break\n",
    "        if has_reset:\n",
    "            consec = 0\n",
    "        else:\n",
    "            consec += 1\n",
    "            if consec > max_consec:\n",
    "                max_consec = consec\n",
    "    return max_consec\n",
    "\n",
    "\n",
    "@nb.njit(cache=True)\n",
    "def _linfit_s0(x, y):\n",
    "    \"\"\"\n",
    "    y = a + b*x  (OLS)\n",
    "    return (ok, a, b, s0)\n",
    "    \"\"\"\n",
    "    n = x.size\n",
    "    sx = 0.0\n",
    "    sy = 0.0\n",
    "    sxx = 0.0\n",
    "    sxy = 0.0\n",
    "    for i in range(n):\n",
    "        sx += x[i]\n",
    "        sy += y[i]\n",
    "        sxx += x[i]*x[i]\n",
    "        sxy += x[i]*y[i]\n",
    "\n",
    "    denom = n*sxx - sx*sx\n",
    "    if denom == 0.0:\n",
    "        return 0, 0.0, 0.0, np.nan\n",
    "\n",
    "    b = (n*sxy - sx*sy)/denom\n",
    "    a = (sy - b*sx)/n\n",
    "\n",
    "    if not np.isfinite(a) or not np.isfinite(b):\n",
    "        return 0, 0.0, 0.0, np.nan\n",
    "    if b >= 0.0:\n",
    "        return 0, a, b, np.nan\n",
    "\n",
    "    s0 = -a/b\n",
    "    if (not np.isfinite(s0)) or (s0 <= 0.0):\n",
    "        return 0, a, b, np.nan\n",
    "\n",
    "    return 1, a, b, s0\n",
    "\n",
    "\n",
    "@nb.njit(cache=True)\n",
    "def _s0_one_pixel(cwd, X, year_slices, nbins, q,\n",
    "                  min_event_steps, min_valid_bins, min_points_total, runaway_years):\n",
    "    \"\"\"\n",
    "    cwd, X: 1D length T\n",
    "    return s0 (float32) or nan\n",
    "    \"\"\"\n",
    "    # runaway check\n",
    "    if _count_runaway_years(cwd, year_slices) >= runaway_years:\n",
    "        return np.nan\n",
    "\n",
    "    T = cwd.size\n",
    "    nY = year_slices.shape[0]\n",
    "\n",
    "    # pooling arrays (最多 T 点)\n",
    "    pool_cwd = np.empty(T, dtype=np.float32)\n",
    "    pool_x   = np.empty(T, dtype=np.float32)\n",
    "    n_pool = 0\n",
    "    gmax = 0.0\n",
    "\n",
    "    # per-year largest event (在每年 slice 内找最大值窗口)\n",
    "    for yi in range(nY):\n",
    "        s = year_slices[yi,0]\n",
    "        e = year_slices[yi,1]\n",
    "        ok, st, ed, cwdmax = _event_window_one_year(cwd[s:e], min_event_steps)\n",
    "        if ok == 0:\n",
    "            continue\n",
    "\n",
    "        # 把该窗口内点加入 pool\n",
    "        for tt in range(s+st, s+ed):\n",
    "            c = cwd[tt]\n",
    "            x = X[tt]\n",
    "            if np.isfinite(c) and np.isfinite(x) and c >= 0.0:\n",
    "                pool_cwd[n_pool] = c\n",
    "                pool_x[n_pool] = x\n",
    "                n_pool += 1\n",
    "                if c > gmax:\n",
    "                    gmax = c\n",
    "\n",
    "    if n_pool < min_points_total or (not np.isfinite(gmax)) or gmax <= 0.0:\n",
    "        return np.nan\n",
    "\n",
    "    # ===== 分箱：先 count，再按 bin regroup（O(n_pool)）\n",
    "    counts = np.zeros(nbins, dtype=np.int32)\n",
    "    bin_id = np.empty(n_pool, dtype=np.int32)\n",
    "\n",
    "    for i in range(n_pool):\n",
    "        b = int(pool_cwd[i] / gmax * nbins)\n",
    "        if b < 0:\n",
    "            b = 0\n",
    "        elif b >= nbins:\n",
    "            b = nbins - 1\n",
    "        bin_id[i] = b\n",
    "        counts[b] += 1\n",
    "\n",
    "    # prefix sum -> offsets\n",
    "    offsets = np.empty(nbins, dtype=np.int32)\n",
    "    pos = 0\n",
    "    for b in range(nbins):\n",
    "        offsets[b] = pos\n",
    "        pos += counts[b]\n",
    "\n",
    "    # regroup X by bin in one array\n",
    "    xgrp = np.empty(n_pool, dtype=np.float32)\n",
    "    cursor = offsets.copy()\n",
    "    for i in range(n_pool):\n",
    "        b = bin_id[i]\n",
    "        p = cursor[b]\n",
    "        xgrp[p] = pool_x[i]\n",
    "        cursor[b] += 1\n",
    "\n",
    "    # 对每个 bin：sort in-place -> 取 q 分位\n",
    "    # 同时构建回归点 (xbincenter, Xq)\n",
    "    xb = np.empty(nbins, dtype=np.float32)\n",
    "    yq = np.empty(nbins, dtype=np.float32)\n",
    "    n_valid = 0\n",
    "\n",
    "    for b in range(nbins):\n",
    "        n = counts[b]\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        st = offsets[b]\n",
    "        ed = st + n\n",
    "\n",
    "        # in-place sort\n",
    "        xgrp[st:ed].sort()\n",
    "\n",
    "        # q-quantile index（nearest-rank风格）\n",
    "        k = int(math.ceil(q * n) - 1)\n",
    "        if k < 0:\n",
    "            k = 0\n",
    "        if k >= n:\n",
    "            k = n - 1\n",
    "\n",
    "        xq = xgrp[st + k]\n",
    "        if not np.isfinite(xq):\n",
    "            continue\n",
    "\n",
    "        # bin center\n",
    "        center = (b + 0.5) / nbins * gmax\n",
    "        xb[n_valid] = center\n",
    "        yq[n_valid] = xq\n",
    "        n_valid += 1\n",
    "\n",
    "    if n_valid < min_valid_bins:\n",
    "        return np.nan\n",
    "\n",
    "    ok, a, b, s0 = _linfit_s0(xb[:n_valid], yq[:n_valid])\n",
    "    if ok == 0:\n",
    "        return np.nan\n",
    "    return np.float32(s0)\n",
    "\n",
    "\n",
    "@nb.njit(parallel=True, cache=True)\n",
    "def s0_tile(cwd3d, X3d, year_slices, nbins, q,\n",
    "            min_event_steps, min_valid_bins, min_points_total, runaway_years):\n",
    "    \"\"\"\n",
    "    cwd3d, X3d: (T, Y, X)\n",
    "    return s0_2d: (Y, X)\n",
    "    \"\"\"\n",
    "    T, Y, X = cwd3d.shape\n",
    "    out = np.empty((Y, X), dtype=np.float32)\n",
    "    n_pix = Y * X\n",
    "\n",
    "    for p in nb.prange(n_pix):\n",
    "        j = p // X\n",
    "        i = p - j * X\n",
    "        out[j, i] = _s0_one_pixel(cwd3d[:, j, i], X3d[:, j, i],\n",
    "                                  year_slices, nbins, q,\n",
    "                                  min_event_steps, min_valid_bins, min_points_total, runaway_years)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72232fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SdEF tile: nan nan nan% 1.0\n",
      "SdSIF tile: nan nan nan% 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3336617/670419628.py:12: RuntimeWarning: All-NaN slice encountered\n",
      "  print(\"SdEF tile:\", np.nanmin(s0_def), np.nanmax(s0_def), \"nan%\", np.isnan(s0_def).mean())\n",
      "/tmp/ipykernel_3336617/670419628.py:13: RuntimeWarning: All-NaN slice encountered\n",
      "  print(\"SdSIF tile:\", np.nanmin(s0_dsif), np.nanmax(s0_dsif), \"nan%\", np.isnan(s0_dsif).mean())\n"
     ]
    }
   ],
   "source": [
    "# 选一个 tile\n",
    "y0,y1,x0,x1 = TILES[0]\n",
    "cwd_t, def_t, dsif_t = load_tile(y0,y1,x0,x1)\n",
    "\n",
    "# 运行 numba（第一次会编译，稍慢；后面很快）\n",
    "s0_def  = s0_tile(cwd_t, def_t, YEAR_SLICES, NBINS, Q,\n",
    "                  MIN_EVENT_STEPS, MINVALIDBINS, MINPOINTSTOTAL, RUNAWAY_YEARS)\n",
    "\n",
    "s0_dsif = s0_tile(cwd_t, dsif_t, YEAR_SLICES, NBINS, Q,\n",
    "                  MIN_EVENT_STEPS, MINVALIDBINS, MINPOINTSTOTAL, RUNAWAY_YEARS)\n",
    "\n",
    "print(\"SdEF tile:\", np.nanmin(s0_def), np.nanmax(s0_def), \"nan%\", np.isnan(s0_def).mean())\n",
    "print(\"SdSIF tile:\", np.nanmin(s0_dsif), np.nanmax(s0_dsif), \"nan%\", np.isnan(s0_dsif).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /tera04/zhwei/xionghui/bedrock/data/out_tiles/SdEF_y0000-0300_x0000-0300.nc4 /tera04/zhwei/xionghui/bedrock/data/out_tiles/SdSIF_y0000-0300_x0000-0300.nc4\n"
     ]
    }
   ],
   "source": [
    "def write_tile(y0,y1,x0,x1, s0_def, s0_dsif):\n",
    "    lat_tile = lat[y0:y1]\n",
    "    lon_tile = lon[x0:x1]\n",
    "\n",
    "    da_def = xr.DataArray(s0_def, dims=(\"lat\",\"lon\"),\n",
    "                          coords={\"lat\": lat_tile, \"lon\": lon_tile},\n",
    "                          name=\"SdEF\").astype(\"float32\")\n",
    "    da_sif = xr.DataArray(s0_dsif, dims=(\"lat\",\"lon\"),\n",
    "                          coords={\"lat\": lat_tile, \"lon\": lon_tile},\n",
    "                          name=\"SdSIF\").astype(\"float32\")\n",
    "\n",
    "    tile_tag = f\"y{y0:04d}-{y1:04d}_x{x0:04d}-{x1:04d}\"\n",
    "    f_def = OUT_TILE_DIR / f\"SdEF_{tile_tag}.nc\"\n",
    "    f_sif = OUT_TILE_DIR / f\"SdSIF_{tile_tag}.nc\"\n",
    "\n",
    "    xr.Dataset({\"SdEF\": da_def}).to_netcdf(f_def, engine=\"netcdf4\", format=\"NETCDF4\",\n",
    "                                          encoding={\"SdEF\": ENC_2D})\n",
    "    xr.Dataset({\"SdSIF\": da_sif}).to_netcdf(f_sif, engine=\"netcdf4\", format=\"NETCDF4\",\n",
    "                                            encoding={\"SdSIF\": ENC_2D})\n",
    "\n",
    "    return f_def, f_sif\n",
    "\n",
    "f1, f2 = write_tile(y0,y1,x0,x1, s0_def, s0_dsif)\n",
    "print(\"Wrote:\", f1, f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484252d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] 10/288 done, fail=0\n",
      "[PROGRESS] 20/288 done, fail=0\n",
      "[PROGRESS] 30/288 done, fail=0\n",
      "[PROGRESS] 40/288 done, fail=0\n",
      "[PROGRESS] 50/288 done, fail=0\n",
      "[PROGRESS] 60/288 done, fail=0\n",
      "[PROGRESS] 70/288 done, fail=0\n",
      "[PROGRESS] 80/288 done, fail=0\n",
      "[PROGRESS] 90/288 done, fail=0\n",
      "[PROGRESS] 100/288 done, fail=0\n",
      "[PROGRESS] 110/288 done, fail=0\n",
      "[PROGRESS] 120/288 done, fail=0\n",
      "[PROGRESS] 130/288 done, fail=0\n",
      "[PROGRESS] 140/288 done, fail=0\n",
      "[PROGRESS] 150/288 done, fail=0\n",
      "[PROGRESS] 160/288 done, fail=0\n",
      "[PROGRESS] 170/288 done, fail=0\n",
      "[PROGRESS] 180/288 done, fail=0\n",
      "[PROGRESS] 190/288 done, fail=0\n",
      "[PROGRESS] 200/288 done, fail=0\n",
      "[PROGRESS] 210/288 done, fail=0\n",
      "[PROGRESS] 220/288 done, fail=0\n",
      "[PROGRESS] 230/288 done, fail=0\n",
      "[PROGRESS] 240/288 done, fail=0\n",
      "[PROGRESS] 250/288 done, fail=0\n",
      "[PROGRESS] 260/288 done, fail=0\n",
      "[PROGRESS] 270/288 done, fail=0\n",
      "[PROGRESS] 280/288 done, fail=0\n",
      "All done. fail= 0\n"
     ]
    }
   ],
   "source": [
    "def worker_one_tile(tile_id):\n",
    "    y0,y1,x0,x1 = TILES[tile_id]\n",
    "    tile_tag = f\"y{y0:04d}-{y1:04d}_x{x0:04d}-{x1:04d}\"\n",
    "    f_def = OUT_TILE_DIR / f\"SdEF_{tile_tag}.nc\"\n",
    "    f_sif = OUT_TILE_DIR / f\"SdSIF_{tile_tag}.nc\"\n",
    "\n",
    "    # checkpoint: 已存在则跳过\n",
    "    if f_def.exists() and f_sif.exists():\n",
    "        return tile_id, \"SKIP\"\n",
    "\n",
    "    # 每个进程独立打开（关键）\n",
    "    ds_c = xr.open_dataset(CWD_PATH, engine=\"netcdf4\")\n",
    "    ds_e = xr.open_dataset(dEF_PATH, engine=\"netcdf4\")\n",
    "    ds_s = xr.open_dataset(dSIF_PATH, engine=\"netcdf4\")\n",
    "\n",
    "    cwd  = ds_c[VAR_CWD].isel(lat=slice(y0,y1), lon=slice(x0,x1)).transpose(\"time\",\"lat\",\"lon\").load().data.astype(np.float32)\n",
    "    dEF  = ds_e[VAR_dEF].isel(lat=slice(y0,y1), lon=slice(x0,x1)).transpose(\"time\",\"lat\",\"lon\").load()\n",
    "    dSIF = ds_s[VAR_dSIF].isel(lat=slice(y0,y1), lon=slice(x0,x1)).transpose(\"time\",\"lat\",\"lon\").load()\n",
    "\n",
    "    dEF  = dEF.where(dEF != FILL_X).data.astype(np.float32)\n",
    "    dSIF = dSIF.where(dSIF != FILL_X).data.astype(np.float32)\n",
    "\n",
    "    # compute\n",
    "    s0_def  = s0_tile(cwd, dEF,  YEAR_SLICES, NBINS, Q,\n",
    "                      MIN_EVENT_STEPS, MINVALIDBINS, MINPOINTSTOTAL, RUNAWAY_YEARS)\n",
    "    s0_dsif = s0_tile(cwd, dSIF, YEAR_SLICES, NBINS, Q,\n",
    "                      MIN_EVENT_STEPS, MINVALIDBINS, MINPOINTSTOTAL, RUNAWAY_YEARS)\n",
    "\n",
    "    # write\n",
    "    lat_tile = lat[y0:y1]\n",
    "    lon_tile = lon[x0:x1]\n",
    "\n",
    "    da_def = xr.DataArray(s0_def, dims=(\"lat\",\"lon\"),\n",
    "                          coords={\"lat\": lat_tile, \"lon\": lon_tile},\n",
    "                          name=\"SdEF\").astype(\"float32\")\n",
    "    da_sif = xr.DataArray(s0_dsif, dims=(\"lat\",\"lon\"),\n",
    "                          coords={\"lat\": lat_tile, \"lon\": lon_tile},\n",
    "                          name=\"SdSIF\").astype(\"float32\")\n",
    "\n",
    "    xr.Dataset({\"SdEF\": da_def}).to_netcdf(f_def, engine=\"netcdf4\", format=\"NETCDF4\",\n",
    "                                           encoding={\"SdEF\": ENC_2D})\n",
    "    xr.Dataset({\"SdSIF\": da_sif}).to_netcdf(f_sif, engine=\"netcdf4\", format=\"NETCDF4\",\n",
    "                                            encoding={\"SdSIF\": ENC_2D})\n",
    "    return tile_id, \"OK\"\n",
    "\n",
    "\n",
    "# ====== 并行执行 ======\n",
    "N_WORKERS = 24  # 你说至少24进程\n",
    "\n",
    "done = 0\n",
    "fail = 0\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=N_WORKERS) as ex:\n",
    "    futs = {ex.submit(worker_one_tile, tid): tid for tid in range(len(TILES))}\n",
    "    for fut in as_completed(futs):\n",
    "        tid = futs[fut]\n",
    "        try:\n",
    "            tid2, status = fut.result()\n",
    "            done += 1\n",
    "            if status != \"OK\" and status != \"SKIP\":\n",
    "                fail += 1\n",
    "            if done % 10 == 0:\n",
    "                print(f\"[PROGRESS] {done}/{len(TILES)} done, fail={fail}\")\n",
    "        except Exception as e:\n",
    "            fail += 1\n",
    "            print(f\"[FAIL] tile {tid}:\", repr(e))\n",
    "\n",
    "print(\"All done. fail=\", fail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493ef376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote global: /tera04/zhwei/xionghui/bedrock/data/veg_activity/SdEF.nc /tera04/zhwei/xionghui/bedrock/data/veg_activity/SdSIF.nc\n"
     ]
    }
   ],
   "source": [
    "def assemble_global(varname, pattern_prefix, out_path):\n",
    "    files = sorted(OUT_TILE_DIR.glob(f\"{pattern_prefix}_y*-*_x*-*.nc\"))\n",
    "    if len(files) == 0:\n",
    "        raise RuntimeError(\"No tile files found for \" + pattern_prefix)\n",
    "\n",
    "    # open_mfdataset 自动按坐标拼接（要求 tile 坐标不重叠且完整）\n",
    "    ds = xr.open_mfdataset(files, combine=\"by_coords\", engine=\"netcdf4\")\n",
    "    da = ds[varname].astype(\"float32\")\n",
    "\n",
    "    # 输出 chunk 可自行调\n",
    "    enc = {varname: dict(zlib=True, complevel=4, dtype=\"float32\", chunksizes=(600,600))}\n",
    "    xr.Dataset({varname: da}).to_netcdf(out_path, engine=\"netcdf4\", format=\"NETCDF4\", encoding=enc)\n",
    "    return out_path\n",
    "\n",
    "out_def = assemble_global(\"SdEF\", \"SdEF\", OUT_GLOBAL_DIR / \"SdEF.nc\")\n",
    "out_sif = assemble_global(\"SdSIF\", \"SdSIF\", OUT_GLOBAL_DIR / \"SdSIF.nc\")\n",
    "print(\"Wrote global:\", out_def, out_sif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c997d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"SdEF\": {\n",
      "    \"nan_frac\": 0.8817354938271605,\n",
      "    \"p01\": 25.294102001190186,\n",
      "    \"p50\": 324.04734802246094,\n",
      "    \"p99\": 24972.2095703125,\n",
      "    \"min\": 0.004365758970379829,\n",
      "    \"max\": 293556928.0\n",
      "  },\n",
      "  \"SdSIF\": {\n",
      "    \"nan_frac\": 0.8932793981481482,\n",
      "    \"p01\": 11.527358474731447,\n",
      "    \"p50\": 348.12701416015625,\n",
      "    \"p99\": 19929.036035156165,\n",
      "    \"min\": 0.0007142720278352499,\n",
      "    \"max\": 477670848.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ds1 = xr.open_dataset(out_def)\n",
    "ds2 = xr.open_dataset(out_sif)\n",
    "\n",
    "SdEF  = ds1[\"SdEF\"].values\n",
    "SdSIF = ds2[\"SdSIF\"].values\n",
    "\n",
    "qc = {\n",
    "    \"SdEF\": {\n",
    "        \"nan_frac\": float(np.isnan(SdEF).mean()),\n",
    "        \"p01\": float(np.nanpercentile(SdEF, 1)),\n",
    "        \"p50\": float(np.nanpercentile(SdEF, 50)),\n",
    "        \"p99\": float(np.nanpercentile(SdEF, 99)),\n",
    "        \"min\": float(np.nanmin(SdEF)),\n",
    "        \"max\": float(np.nanmax(SdEF)),\n",
    "    },\n",
    "    \"SdSIF\": {\n",
    "        \"nan_frac\": float(np.isnan(SdSIF).mean()),\n",
    "        \"p01\": float(np.nanpercentile(SdSIF, 1)),\n",
    "        \"p50\": float(np.nanpercentile(SdSIF, 50)),\n",
    "        \"p99\": float(np.nanpercentile(SdSIF, 99)),\n",
    "        \"min\": float(np.nanmin(SdSIF)),\n",
    "        \"max\": float(np.nanmax(SdSIF)),\n",
    "    }\n",
    "}\n",
    "print(json.dumps(qc, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
